import typing
import os
import fnmatch
import ast

from nb_path import NbPath

FILE_CONTENT_BACKQUOTES = "`````"  # ä¸ç”¨åä¸‰å¼•å·æ˜¯ä¸ºäº†é¿å…ä¸è¢«åˆå¹¶çš„å¦‚æœæœ¬èº«å°±æ˜¯.mdæ–‡ä»¶çš„é‡Œé¢çš„åä¸‰å¼•å·å†²çªï¼Œå¯¼è‡´æ–‡ä»¶å—æå‰åˆ¤æ–­ç»“æŸ

class AiMdGenerator(NbPath):
    """
    An extremely powerful context generator born for AI collaboration.

    This class is designed to revolutionize how developers interact with Large Language
    Models (LLMs). It intelligently merges multiple project source files into a single,
    well-structured, and context-rich Markdown file, providing the AI with a perfect
    and comprehensive project snapshot.

    Key Features:
    1.  **AI Reading Guide**: `add_ai_reading_guide()` adds instructions for AI models
        to better understand the document structure and avoid hallucinations.
    2.  **Project Summary with Core Files Metadata**: `add_project_summary()` extracts
        AST metadata from core files without full source code, helping AI quickly
        grasp the project architecture.
    3.  **File Dependencies Analysis**: `add_file_dependencies()` analyzes import
        relationships between files, showing entry points and core modules.
    4.  **Smart File Merging**: `merge_from_dir()` and `merge_from_files()` with
        .gitignore support, file filtering, and AST metadata extraction.
    5.  **Clear File Boundaries**: Each file is marked with project name and path
        for easy identification by AI models.

    Main Public Methods:
    - `set_project_propery(project_name, project_root)`: Set project info (required first)
    - `add_ai_reading_guide()`: Add AI reading instructions to reduce hallucinations
    - `add_project_summary(project_summary, most_core_source_code_file_list)`: Add summary with core file metadata
    - `add_file_dependencies(file_list)`: Analyze and add file dependency graph
    - `auto_merge_from_python_project_some_files()`: Auto-merge README, setup.py, pyproject.toml
    - `merge_from_files(file_list, as_title)`: Merge specific files
    - `merge_from_dir(dir_name, as_title, ...)`: Merge entire directory with filters
    - `merge_from_files_with_metadata(file_list, as_title, include_ast_metadata, include_file_text)`: Advanced merge with metadata control

    Example:
        >>> from nb_ai_context import AiMdGenerator
        >>> 
        >>> project_name = "my_project"
        >>> project_root = r"D:\\codes\\my_project"
        >>> 
        >>> (
        ...     AiMdGenerator(rf"D:\\ai_docs\\{project_name}_for_ai.md")
        ...     .set_project_propery(project_name=project_name, project_root=project_root)
        ...     .clear_text()
        ...     .add_ai_reading_guide()  # Add AI reading instructions
        ...     .add_project_summary(
        ...         project_summary="This is my awesome project...",
        ...         most_core_source_code_file_list=[
        ...             "src/main.py",
        ...             "src/api.py",
        ...         ]
        ...     )
        ...     .auto_merge_from_python_project_some_files()
        ...     .merge_from_dir(
        ...         relative_dir_name="src",
        ...         as_title=f"{project_name} Source Code",
        ...         use_gitignore=True,
        ...         should_include_suffixes=[".py", ".md"],
        ...         include_ast_metadata=True,
        ...     )
        ...     .show_textfile_info()
        ... )
    """

    """cn description
    ä¸€ä¸ªæå…¶å¼ºå¤§çš„ã€ä¸º AI åä½œè€Œç”Ÿçš„ä¸Šä¸‹æ–‡ç”Ÿæˆå™¨ã€‚

    æ­¤ç±»æ—¨åœ¨å½»åº•æ”¹å˜å¼€å‘è€…ä¸å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„äº¤äº’æ–¹å¼ã€‚å®ƒèƒ½å¤Ÿæ™ºèƒ½åœ°å°†å¤šä¸ªé¡¹ç›®æºæ–‡ä»¶
    åˆå¹¶æˆä¸€ä¸ªç»“æ„æ¸…æ™°ã€ä¸Šä¸‹æ–‡ä¸°å¯Œçš„å•ä¸€ Markdown æ–‡ä»¶ï¼Œä»è€Œä¸º AI æä¾›ä¸€ä¸ªå®Œç¾ã€å…¨é¢çš„é¡¹ç›®å¿«ç…§ã€‚

    æ ¸å¿ƒåŠŸèƒ½ï¼š
    1.  **AI é˜…è¯»æŒ‡å—**ï¼š`add_ai_reading_guide()` ä¸º AI æ¨¡å‹æ·»åŠ é˜…è¯»è¯´æ˜ï¼Œå¸®åŠ©å…¶æ›´å¥½åœ°
        ç†è§£æ–‡æ¡£ç»“æ„ï¼Œå‡å°‘å¹»è§‰ã€‚
    2.  **é¡¹ç›®æ¦‚è¿°ä¸æ ¸å¿ƒæ–‡ä»¶å…ƒæ•°æ®**ï¼š`add_project_summary()` ä»æ ¸å¿ƒæ–‡ä»¶ä¸­æå– AST å…ƒæ•°æ®
        ï¼ˆä¸å«å®Œæ•´æºç ï¼‰ï¼Œå¸®åŠ© AI å¿«é€ŸæŒæ¡é¡¹ç›®æ¶æ„ã€‚
    3.  **æ–‡ä»¶ä¾èµ–åˆ†æ**ï¼š`add_file_dependencies()` åˆ†ææ–‡ä»¶é—´çš„ import ä¾èµ–å…³ç³»ï¼Œ
        å±•ç¤ºå…¥å£æ–‡ä»¶å’Œæ ¸å¿ƒæ¨¡å—ã€‚
    4.  **æ™ºèƒ½æ–‡ä»¶åˆå¹¶**ï¼š`merge_from_dir()` å’Œ `merge_from_files()` æ”¯æŒ .gitignoreã€
        æ–‡ä»¶è¿‡æ»¤å’Œ AST å…ƒæ•°æ®æå–ã€‚
    5.  **æ¸…æ™°çš„æ–‡ä»¶è¾¹ç•Œ**ï¼šæ¯ä¸ªæ–‡ä»¶éƒ½æ ‡è®°äº†é¡¹ç›®åå’Œè·¯å¾„ï¼Œæ–¹ä¾¿ AI æ¨¡å‹è¯†åˆ«ã€‚

    ä¸»è¦å…¬å¼€æ–¹æ³•ï¼š
    - `set_project_propery(project_name, project_root)`: è®¾ç½®é¡¹ç›®ä¿¡æ¯ï¼ˆå¿…é¡»é¦–å…ˆè°ƒç”¨ï¼‰
    - `add_ai_reading_guide()`: æ·»åŠ  AI é˜…è¯»æŒ‡å—ä»¥å‡å°‘å¹»è§‰
    - `add_project_summary(project_summary, most_core_source_code_file_list)`: æ·»åŠ é¡¹ç›®æ¦‚è¿°å’Œæ ¸å¿ƒæ–‡ä»¶å…ƒæ•°æ®
    - `add_file_dependencies(file_list)`: åˆ†æå¹¶æ·»åŠ æ–‡ä»¶ä¾èµ–å›¾
    - `auto_merge_from_python_project_some_files()`: è‡ªåŠ¨åˆå¹¶ READMEã€setup.pyã€pyproject.toml
    - `merge_from_files(file_list, as_title)`: åˆå¹¶æŒ‡å®šæ–‡ä»¶
    - `merge_from_dir(dir_name, as_title, ...)`: åˆå¹¶æ•´ä¸ªç›®å½•ï¼ˆæ”¯æŒè¿‡æ»¤ï¼‰
    - `merge_from_files_with_metadata(...)`: é«˜çº§åˆå¹¶ï¼Œå¯æ§åˆ¶å…ƒæ•°æ®å’Œæºç 

    """

    suffix__lang_map = {
        ".py": "python",
        ".md": "markdown",
        ".txt": "text",
        ".json": "json",
        ".yaml": "yaml",
        ".yml": "yaml",
        ".xml": "xml",
        ".html": "html",
        ".css": "css",
        ".js": "javascript",
        ".ts": "typescript",
        ".jsx": "javascript",
        ".tsx": "typescript",
        ".vue": "vue",
        ".php": "php",
        ".java": "java",
        ".c": "c",
        ".cpp": "cpp",
        ".h": "h",
        ".hpp": "hpp",
        ".cs": "csharp",
        ".vb": "vb",
        ".sql": "sql",
        ".bat": "batch",
        ".sh": "shell",
        ".ps1": "powershell",
        ".psm1": "powershell",
        ".psd1": "powershell",
        ".pssc": "powershell",
        ".psscx": "powershell",
    }

    def set_project_propery(self, project_name: str, project_root: typing.Union[os.PathLike, str] ) -> "AiMdGenerator":
        """Sets the project name for the current markdown file."""
        self.project_name = project_name
        self.project_root = project_root
        return self
    
    def _check_project_name(self) -> "AiMdGenerator":
        """Checks if the project name is set."""
        if not hasattr(self, 'project_name'):
            raise ValueError("Project name is not set. Please call set_project_name() first.")
        return self

    def add_ai_reading_guide(self) -> "AiMdGenerator":
        """
        æ·»åŠ  AI é˜…è¯»æŒ‡å—ï¼Œå¸®åŠ© AI å¤§æ¨¡å‹æ›´å¥½åœ°ç†è§£æ–‡æ¡£ç»“æ„
        
        å»ºè®®åœ¨ clear_text() ä¹‹åã€add_project_summary() ä¹‹å‰è°ƒç”¨
        """
        self._check_project_name()
        guide = f"""# ğŸ¤– AI Reading Guide for Project: {self.project_name}

> **Important Notice for AI Models**: This document contains the complete source code and documentation for the `{self.project_name}` project. Please read this guide carefully before analyzing the content.

## ğŸ“– Document Structure

This markdown document is structured as follows:

1. **Project Summary** (`# markdown content namespace: xxx project summary`)
   - Brief project description
   - Core source files metadata (AST-parsed class/function signatures without full source code)
   - File dependencies analysis

2. **Project Root Files** (`# markdown content namespace: xxx Project Root Dir Some Files`)
   - README.md, pyproject.toml, setup.py, etc.

3. **Source Code Sections** (`# markdown content namespace: xxx codes/examples/...`)
   - File Tree: Shows directory structure
   - Included Files: Lists all files in this section
   - Full source code with AST metadata for Python files

## ğŸ” How to Identify File Boundaries

- Each file starts with: `--- **start of file: <path>** (project: {self.project_name}) ---`
- Each file ends with: `--- **end of file: <path>** (project: {self.project_name}) ---`
- All file paths are relative to the project root

## âš ï¸ Important Notes

1. **Do NOT hallucinate**: Only reference code, classes, functions, and APIs that actually exist in this document
2. **Check file paths**: When suggesting code changes, always verify the file path exists in the File Tree
3. **Respect the project structure**: The File Tree shows the actual directory layout
4. **AST Metadata**: Python files include parsed metadata (imports, classes, methods) before the full source code

---

"""
        self.append_text(guide)
        return self

    def add_project_summary(
        self, 
        project_summary: str, 
        most_core_source_code_file_list: typing.List[str] = None,
        project_root: typing.Union[os.PathLike, str] = None,
    ) -> "AiMdGenerator":
        """
        Adds a project summary to the current markdown file.
        
        Args:
            project_summary: é¡¹ç›®æ¦‚è¿°æ–‡æœ¬
            project_root: é¡¹ç›®æ ¹ç›®å½•ï¼ˆå¦‚æœæä¾›äº† most_core_source_code_file_listï¼‰
            most_core_source_code_file_list: æœ€æ ¸å¿ƒçš„æºç æ–‡ä»¶åˆ—è¡¨ï¼ˆç›¸å¯¹è·¯å¾„ï¼‰
                                             åªæå–è¿™äº›æ–‡ä»¶çš„ AST å…ƒæ•°æ®ï¼Œä¸åŒ…å«å®Œæ•´æºç 
        
        Example:
            >>> (
            ...     AiMdGenerator("output.md")
            ...     .set_project_name("my_project")
            ...     .clear_text()
            ...     .add_project_summary(
            ...         project_summary="è¿™æ˜¯ä¸€ä¸ªä¼˜ç§€çš„é¡¹ç›®...",
            ...         project_root="/path/to/project",
            ...         most_core_source_code_file_list=["src/main.py", "src/api.py"],
            ...     )
            ... )
        """
        self._check_project_name()
        project_root =  project_root or self.project_root 
        str_list = [f"# markdown content namespace: {self.project_name} project summary \n\n"]
        str_list.append(project_summary)
        # str_list.append("\n---\n\n")
        
        # å¦‚æœæä¾›äº†æ ¸å¿ƒæ–‡ä»¶åˆ—è¡¨ï¼Œæå–å®ƒä»¬çš„å…ƒæ•°æ®ï¼ˆä¸åŒ…å«æºç ï¼‰
        if most_core_source_code_file_list and project_root:
            # str_list.append("\n---\n\n")
            str_list.append(f"\n## ğŸ“‹ {self.project_name} most core source files metadata (Entry Points)\n\n")
            str_list.append(f"ä»¥ä¸‹æ˜¯é¡¹ç›® {self.project_name} æœ€æ ¸å¿ƒçš„å…¥å£æ–‡ä»¶çš„ç»“æ„åŒ–å…ƒæ•°æ®ï¼Œå¸®åŠ©å¿«é€Ÿç†è§£é¡¹ç›®æ¶æ„ï¼š\n\n")
            most_core_source_code_file_list_str = ''
            for relative_file_name in most_core_source_code_file_list:
                most_core_source_code_file_list_str += f"- `{relative_file_name}`\n"
            str_list.append(f'\n### the project {self.project_name} most core source code files as follows: \n{most_core_source_code_file_list_str}')
            
            
            project_root_path = NbPath(project_root).resolve()
            
            for relative_file_name in most_core_source_code_file_list:
                file = (project_root_path / relative_file_name).resolve()
                if not file.exists():
                    raise FileNotFoundError(f"File {file} not found.")

                if file.is_file() and file.is_text() and file.suffix == ".py":
                    relative_file_name_posix = file.relative_to(project_root_path).as_posix()
                    
                    self.logger.info(f"æå–æ ¸å¿ƒæ–‡ä»¶å…ƒæ•°æ®ï¼ˆæ— æºç ï¼‰: {relative_file_name_posix}")
                    
                    # åªæå–å…ƒæ•°æ®ï¼Œä¸åŒ…å«æºç 
                    metadata = self._parse_python_file_ast(file)
                    metadata_md = self._format_py_metadata_as_markdown(metadata, relative_file_name_posix)
                    str_list.append(metadata_md)
                    str_list.append("\n")
        
        self.append_text('\n'.join(str_list))
        self.add_file_dependencies(most_core_source_code_file_list)
        return self

    def _generate_markdown_header(self, as_title: str, file_text_list: list) -> list:
        """ç”ŸæˆåŒ…å«æ–‡ä»¶æ ‘å’Œæ–‡ä»¶åˆ—è¡¨çš„ Markdown å¤´éƒ¨"""
        str_list = [f"# markdown content namespace: {as_title} \n\n"]
        
        # ä»æ–‡ä»¶åˆ—è¡¨ä¸­æå–å…¬å…±ç›®å½•å‰ç¼€ï¼Œç”¨äºæ˜¾ç¤ºç›¸å¯¹ç›®å½•ä¿¡æ¯
        if file_text_list:
            all_paths = [item[1] for item in file_text_list]
            # æ‰¾å‡ºå…¬å…±ç›®å½•å‰ç¼€
            if all_paths:
                first_parts = all_paths[0].split('/')
                common_prefix_parts = []
                for i, part in enumerate(first_parts[:-1]):  # ä¸åŒ…æ‹¬æ–‡ä»¶å
                    if all(p.split('/')[i] == part if i < len(p.split('/')) else False for p in all_paths):
                        common_prefix_parts.append(part)
                    else:
                        break
                relative_dir = '/'.join(common_prefix_parts) if common_prefix_parts else '.'
            else:
                relative_dir = '.'
        else:
            relative_dir = '.'

        # 1. ç”Ÿæˆæ–‡ä»¶æ ‘
        str_list.append(f"## {self.project_name} File Tree (relative dir: `{relative_dir}`)\n\n")
        str_list.append(f"{FILE_CONTENT_BACKQUOTES}\n")
        tree = {}
        sorted_paths = sorted([item[1] for item in file_text_list])
        for path in sorted_paths:
            parts = path.split('/')
            current_level = tree
            for part in parts:
                if part not in current_level:
                    current_level[part] = {}
                current_level = current_level[part]

        def format_tree(node, prefix=""):
            lines = []
            entries = sorted(node.keys())
            for i, entry in enumerate(entries):
                connector = "â”œâ”€â”€ " if i < len(entries) - 1 else "â””â”€â”€ "
                lines.append(f"{prefix}{connector}{entry}")
                if node[entry]:
                    extension = "â”‚   " if i < len(entries) - 1 else "    "
                    lines.extend(format_tree(node[entry], prefix + extension))
            return lines

        str_list.extend(format_tree(tree))
        str_list.append(f"\n{FILE_CONTENT_BACKQUOTES}\n\n---\n\n")

        # 2. ç”Ÿæˆæ–‡ä»¶åˆ—è¡¨
        str_list.append(f"## {self.project_name} (relative dir: `{relative_dir}`)  Included Files (total: {len(file_text_list)} files)\n\n")
        for _, relative_file_name_posix, _, _ in file_text_list:
            str_list.append(f"- `{relative_file_name_posix}`\n")
        str_list.append("\n---\n\n")

        return str_list

    def auto_merge_from_python_project_some_files(self, project_root: typing.Union[os.PathLike, str] = None) -> 'AiMdGenerator':
        """è‡ªåŠ¨åˆå¹¶é¡¹ç›®æ ¹ç›®å½•ä¸‹çš„ readme.md æˆ–è€…ReADME.md ä»¥åŠsetup.py å’Œ pyproject.toml ï¼Œå¦‚æœæœ‰å°±æ·»åŠ """
        self._check_project_name()
        project_root =  project_root or self.project_root
        file_merge_list = []
        
        # å®šä¹‰è¦æŸ¥æ‰¾çš„æ ¹ç›®å½•æ–‡ä»¶
        root_files_to_check = [
            "README.md",
            # "readme.md",
            "setup.py",
            "pyproject.toml"
        ]
        
        # æ£€æŸ¥æ¯ä¸ªæ–‡ä»¶æ˜¯å¦å­˜åœ¨ï¼Œå¦‚æœå­˜åœ¨åˆ™æ·»åŠ åˆ°åˆå¹¶åˆ—è¡¨ä¸­
        project_root_path = NbPath(project_root).resolve()
        for filename in root_files_to_check:
            file_path = project_root_path / filename
            if file_path.is_file() and file_path.is_text():
                file_merge_list.append(filename)
                
        self.merge_from_files(file_merge_list, f"{self.project_name} Project Root Dir Some Files",project_root, )
        return self

    def merge_from_files(
        self,
        relative_file_name_list: typing.List[str],
        as_title: str,
        project_root: typing.Union[os.PathLike, str] = None,
    ) -> "AiMdGenerator":
        """Merges the content of the given files into the current markdown file.
        the current markdown file will be used to upload to ai model for code review and learning.
        """
        self._check_project_name()
        project_root =  project_root or self.project_root
        file_text_list = []
        project_root_path = NbPath(project_root).resolve()
        for relative_file_name in relative_file_name_list:
            file = (project_root_path / relative_file_name).resolve()
            if not file.exists():
                raise FileNotFoundError(f"File {file} not found.")
            if file.is_file() and file.is_text():
                relative_file_name_posix = file.relative_to(
                    project_root_path
                ).as_posix()
                try:
                    text = file.read_text()
                except Exception as e:
                    self.logger.error(f"Error reading file {file}: {e}")
                    text = ""
                file_text_list.append(
                    [file, relative_file_name_posix, file.suffix, text]
                )
                self.logger.debug(f"need merged file: {file}")
            else:
                raise ValueError(f"File {file} is not a text file.")
        str_list = []
        if file_text_list:
            # è°ƒç”¨æ–°å‡½æ•°ç”Ÿæˆå¤´éƒ¨
            str_list.extend(self._generate_markdown_header(as_title, file_text_list))


        for file, relative_file_name_posix, suffix, text in file_text_list:
            # 2. Remove the debug print statement.
            # print(f'file: {file}, relative_file_name_posix: {relative_file_name_posix}, suffix: {suffix}, text: {text}')
            str_list.append(f"--- **start of file: {relative_file_name_posix}** (project: {self.project_name}) --- \n")
            # 3. Handle .md files separately to ensure their content is rendered correctly.
            #    Other file types are wrapped in code blocks.
            # if suffix == ".md":
            #     str_list.append(text + "\n")
            # else:
            #     lang = self.suffix__lang_map.get(suffix, "text")
            #     str_list.append(f"{FILE_CONTENT_BACKQUOTES}{lang}\n{text}\n{FILE_CONTENT_BACKQUOTES}\n")
            lang = self.suffix__lang_map.get(suffix, "text")
            str_list.append(f"{FILE_CONTENT_BACKQUOTES}{lang}\n{text}\n{FILE_CONTENT_BACKQUOTES}\n")

            str_list.append(f"--- **end of file: {relative_file_name_posix}** (project: {self.project_name}) --- \n")
            str_list.append("---\n\n")

        # with self.open(mode="a", encoding="utf-8") as f:
        #     f.write("\n".join(str_list))
        self.append_text('\n'.join(str_list))
        self.ensure_utf8_bom()
        return self
        
        
    def merge_from_dir(
        self,
        relative_dir_name: str,
        as_title: str,
        project_root: typing.Union[os.PathLike, str] = None,
        should_include_suffixes: typing.List[str] = [],
        excluded_dir_name_list: typing.List[str] = [],
        excluded_file_name_list: typing.List[str] = [],
        use_gitignore: bool = True,
        dry_run: bool = False,
        include_ast_metadata: bool = True,
        include_file_text: bool = True,
    ) -> "AiMdGenerator":
        """Merges the content of the given directory into the current file."""
        project_root =  project_root or self.project_root
        project_root_path = NbPath(project_root).resolve()
        target_dir_path = (project_root_path / relative_dir_name).resolve()
        if not target_dir_path.exists():
            raise FileNotFoundError(f"Directory {target_dir_path} not found.")

        # Use sets for efficient lookups
        excluded_dir_paths = {
            (project_root_path / d).resolve() for d in excluded_dir_name_list
        }
        excluded_file_paths = {
            (project_root_path / f).resolve() for f in excluded_file_name_list
        }

        ignore_patterns = []
        if use_gitignore:
            try:
                gitignore_path = project_root_path.find_git_root() / ".gitignore"
                if gitignore_path.is_file():
                    self.logger.debug(f"Using .gitignore rules from: {gitignore_path}")
                    with open(gitignore_path, "r", encoding="utf-8") as f:
                        for line in f:
                            line = line.strip()
                            if line and not line.startswith("#"):
                                # Gitignore patterns always use forward slashes.
                                # We will compare against the posix version of the relative path
                                # for cross-platform reliability.
                                ignore_patterns.append(line)
            except FileNotFoundError:
                self.logger.warning("use_gitignore is True, but no .git/ or .gitignore file found.")

        relative_paths_to_include = []
        for path_obj in target_dir_path.rglob("*"):
            # Automatically exclude directories starting with a dot at the project root
            try:
                first_part = path_obj.relative_to(project_root_path).parts[0]
                if first_part.startswith('.'):
                    continue
            except (ValueError, IndexError):
                continue
            # Check if the path is within any of the excluded directories
            is_in_excluded_dir = any(
                path_obj == excluded_dir or excluded_dir in path_obj.parents
                for excluded_dir in excluded_dir_paths
            )
            if is_in_excluded_dir:
                continue

            # Check if the path matches any gitignore patterns.
            # Convert the relative path to a posix-style string for reliable matching.
            relative_to_root = path_obj.relative_to(project_root_path)
            relative_posix_path = relative_to_root.as_posix()
            # Use fnmatch for robust gitignore-style pattern matching.
            is_ignored = False
            for p in ignore_patterns:
                # If a pattern does not contain a slash, it matches in any directory.
                # e.g., 'test_git_ignore1.py' should match 'nb_path/example_dir/test_git_ignore1.py'
                if '/' not in p.strip('/'):
                    p_glob = f"**/{p.strip('/')}"
                else:
                    p_glob = p
                if fnmatch.fnmatch(relative_posix_path, p_glob) or fnmatch.fnmatch(relative_posix_path, p):
                    is_ignored = True
                    break
            if is_ignored:
                self.logger.debug(f"Ignoring {relative_to_root} due to .gitignore rule.")
                continue

            if path_obj.is_file():
                # Check if the file itself is excluded
                if path_obj.resolve() in excluded_file_paths:
                    continue
                # Check if the file is a text file
                if not path_obj.is_text():
                    continue
                # Check if the suffix is in the inclusion list (if the list is not empty)
                if (
                    should_include_suffixes
                    and path_obj.suffix not in should_include_suffixes
                ):
                    continue
                relative_paths_to_include.append(
                    path_obj.relative_to(project_root_path).as_posix()
                )

        if dry_run:
            print("\n--- [DRY RUN] AiMdGenerator Execution Plan ---")
            print(f"\nâœ… {len(relative_paths_to_include)} files would be INCLUDED in '{self.name}':")
            for p in sorted(relative_paths_to_include):
                print(f"  - {p}")
            print("\n--- End of DRY RUN ---")
            return self
        else:
            # ä½¿ç”¨å¸¦å…ƒæ•°æ®çš„æ–¹æ³•
            return self.merge_from_files_with_metadata(
                relative_paths_to_include, 
                as_title,
                project_root=project_root,
                include_ast_metadata=include_ast_metadata,
                include_file_text=include_file_text,
            )

    def merge_dir_of_package_examples(self):
        """åˆå¹¶åŒ…çš„examplesç›®å½•åˆ°å½“å‰markdownæ–‡ä»¶"""
        self._check_project_name()
        self.merge_from_dir(
            relative_dir_name=self.project_name,
            use_gitignore=True,
            as_title=f"{self.project_name} codes",
            # åªåŒ…å« .py å’Œ .md æ–‡ä»¶
            should_include_suffixes=[".py", ".md"],
            # æ’é™¤ __pycache__ ç›®å½•å’Œç‰¹å®šçš„æµ‹è¯•æ–‡ä»¶
            excluded_dir_name_list=[],
        ).merge_from_dir(
            relative_dir_name="examples",
            use_gitignore=True,
            as_title=f"{self.project_name} examples",
            # åªåŒ…å« .py å’Œ .md æ–‡ä»¶
            should_include_suffixes=[".py", ".md"],
            # æ’é™¤ __pycache__ ç›®å½•å’Œç‰¹å®šçš„æµ‹è¯•æ–‡ä»¶
            excluded_dir_name_list=[],
            include_ast_metadata=False,
        )
        return self

    def _ast_to_source(self, node) -> str:
        """å°† AST èŠ‚ç‚¹è½¬æ¢ä¸ºæºä»£ç å­—ç¬¦ä¸²ï¼Œå…¼å®¹ Python 3.7+"""
        if node is None:
            return ""
        try:
            # Python 3.9+ æ”¯æŒ ast.unparse
            if hasattr(ast, 'unparse'):
                return ast.unparse(node)
            else:
                # Python 3.7/3.8 çš„å›é€€æ–¹æ¡ˆ
                # å°è¯•ä½¿ç”¨ astor
                try:
                    import astor
                    return astor.to_source(node).strip()
                except ImportError:
                    pass
                
                # ç®€å•çš„æ‰‹å·¥å¤„ç†å¸¸è§æƒ…å†µ
                if isinstance(node, ast.Name):
                    return node.id
                elif isinstance(node, ast.Constant):
                    return repr(node.value)
                elif isinstance(node, ast.Attribute):
                    value = self._ast_to_source(node.value)
                    return f"{value}.{node.attr}"
                elif isinstance(node, ast.Subscript):
                    value = self._ast_to_source(node.value)
                    slice_val = self._ast_to_source(node.slice)
                    return f"{value}[{slice_val}]"
                elif isinstance(node, (ast.List, ast.Tuple)):
                    elts = [self._ast_to_source(e) for e in node.elts]
                    if isinstance(node, ast.List):
                        return f"[{', '.join(elts)}]"
                    else:
                        return f"({', '.join(elts)})"
                else:
                    # å¯¹äºå¤æ‚ç±»å‹ï¼Œè¿”å›ç±»å‹åç§°
                    return node.__class__.__name__
        except Exception:
            return ""

    def _parse_type_annotation(self, annotation) -> str:
        """è§£æç±»å‹æ³¨è§£ï¼Œè¿”å›å­—ç¬¦ä¸²è¡¨ç¤º"""
        return self._ast_to_source(annotation)

    def _extract_function_metadata(self, node: typing.Union[ast.FunctionDef, ast.AsyncFunctionDef]) -> dict:
        """æå–å‡½æ•°/æ–¹æ³•çš„å…ƒæ•°æ®"""
        metadata = {
            "name": node.name,
            "type": "async_function" if isinstance(node, ast.AsyncFunctionDef) else "function",
            "lineno": node.lineno,
            "docstring": ast.get_docstring(node) or "",
            "parameters": [],
            "return_type": self._parse_type_annotation(node.returns),
            "decorators": [self._ast_to_source(dec) for dec in node.decorator_list],
            "is_public": not node.name.startswith("_"),
        }

        # æå–å‚æ•°ä¿¡æ¯
        for arg in node.args.args:
            param_info = {
                "name": arg.arg,
                "type": self._parse_type_annotation(arg.annotation),
                "default": None,
            }
            metadata["parameters"].append(param_info)

        # å¤„ç†é»˜è®¤å‚æ•°
        defaults = node.args.defaults
        if defaults:
            # é»˜è®¤å€¼ä»åå¾€å‰å¯¹åº”å‚æ•°
            num_defaults = len(defaults)
            for i, default in enumerate(defaults):
                param_idx = len(metadata["parameters"]) - num_defaults + i
                if param_idx >= 0:
                    try:
                        metadata["parameters"][param_idx]["default"] = self._ast_to_source(default)
                    except Exception:
                        metadata["parameters"][param_idx]["default"] = "<complex_default>"

        # å¤„ç† *args å’Œ **kwargs
        if node.args.vararg:
            metadata["parameters"].append({
                "name": f"*{node.args.vararg.arg}",
                "type": self._parse_type_annotation(node.args.vararg.annotation),
                "default": None,
            })
        if node.args.kwarg:
            metadata["parameters"].append({
                "name": f"**{node.args.kwarg.arg}",
                "type": self._parse_type_annotation(node.args.kwarg.annotation),
                "default": None,
            })

        return metadata

    def _extract_class_metadata(self, node: ast.ClassDef) -> dict:
        """æå–ç±»çš„å…ƒæ•°æ®"""
        metadata = {
            "name": node.name,
            "type": "class",
            "lineno": node.lineno,
            "docstring": ast.get_docstring(node) or "",
            "bases": [self._ast_to_source(base) for base in node.bases],
            "decorators": [self._ast_to_source(dec) for dec in node.decorator_list],
            "methods": [],
            "properties": [],
            "class_variables": [],
            "is_public": not node.name.startswith("_"),
        }

        # éå†ç±»çš„æˆå‘˜
        for item in node.body:
            if isinstance(item, (ast.FunctionDef, ast.AsyncFunctionDef)):
                method_info = self._extract_function_metadata(item)
                
                # æ£€æŸ¥æ˜¯å¦æ˜¯ property
                is_property = any("property" in dec for dec in method_info["decorators"])
                if is_property:
                    metadata["properties"].append(method_info)
                else:
                    metadata["methods"].append(method_info)
            
            elif isinstance(item, ast.AnnAssign) and isinstance(item.target, ast.Name):
                # ç±»å˜é‡ï¼ˆå¸¦ç±»å‹æ³¨è§£ï¼‰
                value_str = ""
                if item.value:
                    try:
                        value_str = self._ast_to_source(item.value)
                        # é™åˆ¶å€¼çš„é•¿åº¦
                        if len(value_str) > 50:
                            value_str = value_str[:50] + "..."
                    except Exception:
                        value_str = "<value>"
                
                metadata["class_variables"].append({
                    "name": item.target.id,
                    "type": self._parse_type_annotation(item.annotation),
                    "value": value_str,
                    "lineno": item.lineno,
                })
            elif isinstance(item, ast.Assign):
                # ç±»å˜é‡ï¼ˆæ— ç±»å‹æ³¨è§£ï¼‰
                for target in item.targets:
                    if isinstance(target, ast.Name):
                        # æå–å€¼
                        value_str = ""
                        if item.value:
                            try:
                                value_str = self._ast_to_source(item.value)
                                # é™åˆ¶å€¼çš„é•¿åº¦
                                if len(value_str) > 50:
                                    value_str = value_str[:50] + "..."
                            except Exception:
                                value_str = "<value>"
                        
                        metadata["class_variables"].append({
                            "name": target.id,
                            "type": "",
                            "value": value_str,
                            "lineno": item.lineno,
                        })

        return metadata

    def _parse_python_file_ast(self, file_path: NbPath) -> dict:
        """è§£æ Python æ–‡ä»¶çš„ ASTï¼Œæå–æ‰€æœ‰å…ƒæ•°æ®"""
        try:
            source_code = file_path.read_text(encoding="utf-8")
            # ç§»é™¤ BOM (Byte Order Mark) å­—ç¬¦ï¼Œå¦‚æœå­˜åœ¨çš„è¯
            # BOM æ˜¯ U+FEFFï¼Œåœ¨ UTF-8 ç¼–ç ä¸­æ˜¯ \ufeff
            if source_code.startswith('\ufeff'):
                source_code = source_code[1:]
                self.logger.debug(f"Removed BOM from file: {file_path}")
            tree = ast.parse(source_code, filename=str(file_path))
        except Exception as e:
            self.logger.error(f"Failed to parse Python file {file_path}: {e}")
            return {
                "error": str(e),
                "classes": [],
                "functions": [],
                "imports": [],
                "module_docstring": "",
            }

        metadata = {
            "file": str(file_path),
            "module_docstring": ast.get_docstring(tree) or "",
            "classes": [],
            "functions": [],
            "imports": [],
            "constants": [],
        }

        # éå†æ¨¡å—çº§åˆ«çš„èŠ‚ç‚¹
        for node in ast.walk(tree):
            # åªå¤„ç†æ¨¡å—çº§åˆ«çš„å®šä¹‰ï¼ˆé€šè¿‡æ£€æŸ¥çˆ¶èŠ‚ç‚¹ï¼‰
            if isinstance(node, ast.ClassDef):
                # æ£€æŸ¥æ˜¯å¦æ˜¯é¡¶çº§ç±»ï¼ˆä¸åœ¨å…¶ä»–ç±»å†…éƒ¨ï¼‰
                parent = None
                for potential_parent in ast.walk(tree):
                    if isinstance(potential_parent, ast.ClassDef) and node in ast.walk(potential_parent) and node != potential_parent:
                        parent = potential_parent
                        break
                if parent is None:  # é¡¶çº§ç±»
                    metadata["classes"].append(self._extract_class_metadata(node))

            elif isinstance(node, (ast.FunctionDef, ast.AsyncFunctionDef)):
                # æ£€æŸ¥æ˜¯å¦æ˜¯é¡¶çº§å‡½æ•°ï¼ˆä¸åœ¨ç±»å†…éƒ¨ï¼‰
                parent_class = None
                for potential_parent in ast.walk(tree):
                    if isinstance(potential_parent, ast.ClassDef) and node in ast.walk(potential_parent):
                        parent_class = potential_parent
                        break
                if parent_class is None:  # é¡¶çº§å‡½æ•°
                    metadata["functions"].append(self._extract_function_metadata(node))

            elif isinstance(node, (ast.Import, ast.ImportFrom)):
                if isinstance(node, ast.Import):
                    for alias in node.names:
                        metadata["imports"].append({
                            "type": "import",
                            "module": alias.name,
                            "alias": alias.asname,
                            "lineno": node.lineno,
                        })
                else:  # ImportFrom
                    module = node.module or ""
                    for alias in node.names:
                        metadata["imports"].append({
                            "type": "from_import",
                            "module": module,
                            "name": alias.name,
                            "alias": alias.asname,
                            "lineno": node.lineno,
                        })

        return metadata

    def _format_py_metadata_as_markdown(self, metadata: dict, relative_file_name: str) -> str:
        """å°† Python æ–‡ä»¶å…ƒæ•°æ®æ ¼å¼åŒ–ä¸º Markdown"""
        lines = []
        lines.append(f"\n### ğŸ“„ Python File Metadata: `{relative_file_name}`\n")

        # æ¨¡å—æ–‡æ¡£å­—ç¬¦ä¸²
        if metadata.get("module_docstring"):
            lines.append("#### ğŸ“ Module Docstring\n")
            lines.append(FILE_CONTENT_BACKQUOTES)
            lines.append(metadata["module_docstring"])
            lines.append(f"{FILE_CONTENT_BACKQUOTES}\n")

        # å¯¼å…¥ä¿¡æ¯
        if metadata.get("imports"):
            lines.append("#### ğŸ“¦ Imports\n")
            for imp in metadata["imports"]:  # æ˜¾ç¤ºæ‰€æœ‰ importsï¼Œä¸å†é™åˆ¶æ•°é‡
                if imp["type"] == "import":
                    alias_str = f" as {imp['alias']}" if imp['alias'] else ""
                    lines.append(f"- `import {imp['module']}{alias_str}`")
                else:
                    alias_str = f" as {imp['alias']}" if imp['alias'] else ""
                    lines.append(f"- `from {imp['module']} import {imp['name']}{alias_str}`")
            lines.append("")

        # ç±»ä¿¡æ¯
        if metadata.get("classes"):
            lines.append(f"#### ğŸ›ï¸ Classes ({len(metadata['classes'])})\n")
            for cls in metadata["classes"]:
                # åªæ˜¾ç¤ºå…¬æœ‰ç±»æˆ–æ‰€æœ‰ç±»ï¼ˆæ ¹æ®éœ€è¦ï¼‰
                class_header = f"##### ğŸ“Œ `class {cls['name']}"
                if cls["bases"]:
                    class_header += f"({', '.join(cls['bases'])})"
                class_header += "`"
                lines.append(class_header)
                lines.append(f"*Line: {cls['lineno']}*\n")
                
                if cls["docstring"]:
                    # æ˜¾ç¤ºå®Œæ•´çš„ç±»æ–‡æ¡£å­—ç¬¦ä¸²
                    docstring_lines = cls["docstring"].split("\n")
                    lines.append("**Docstring:**")
                    lines.append(FILE_CONTENT_BACKQUOTES)
                    lines.extend(docstring_lines)
                    lines.append(f"{FILE_CONTENT_BACKQUOTES}\n")

                # é¦–å…ˆå•ç‹¬æ˜¾ç¤º __init__ æ–¹æ³•ï¼ˆéå¸¸é‡è¦ï¼‰
                init_method = None
                for method in cls["methods"]:
                    if method["name"] == "__init__":
                        init_method = method
                        break
                
                if init_method:
                    lines.append("**ğŸ”§ Constructor (`__init__`):**")
                    params_str = self._format_parameters(init_method["parameters"])
                    lines.append(f"- `def __init__({params_str})`")
                    
                    # æ˜¾ç¤º __init__ çš„å®Œæ•´æ–‡æ¡£å­—ç¬¦ä¸²
                    if init_method["docstring"]:
                        lines.append("  - **Docstring:**")
                        lines.append(f"  {FILE_CONTENT_BACKQUOTES}")
                        for doc_line in init_method["docstring"].split("\n"):
                            lines.append(f"  {doc_line}")
                        lines.append(f"  {FILE_CONTENT_BACKQUOTES}")
                    
                    # æ˜¾ç¤ºæ¯ä¸ªå‚æ•°çš„è¯¦ç»†ä¿¡æ¯
                    if init_method["parameters"]:
                        lines.append("  - **Parameters:**")
                        for param in init_method["parameters"]:
                            param_name = param["name"]
                            param_type = f": {param['type']}" if param["type"] else ""
                            param_default = f" = {param['default']}" if param["default"] else ""
                            lines.append(f"    - `{param_name}{param_type}{param_default}`")
                    lines.append("")

                # å…¬æœ‰æ–¹æ³•ï¼ˆæ’é™¤ __init__ï¼‰
                public_methods = [m for m in cls["methods"] if m["is_public"] and m["name"] != "__init__"]
                if public_methods:
                    lines.append(f"**Public Methods ({len(public_methods)}):**")
                    for method in public_methods:
                        params_str = self._format_parameters(method["parameters"])
                        return_str = f" -> {method['return_type']}" if method["return_type"] else ""
                        async_str = "async " if method["type"] == "async_function" else ""
                        
                        decorators_str = ""
                        if method["decorators"]:
                            decorators_str = " " + " ".join([f"`{d}`" for d in method["decorators"]])
                        
                        lines.append(f"- `{async_str}def {method['name']}({params_str}){return_str}`{decorators_str}")
                        
                        # æ˜¾ç¤ºå®Œæ•´çš„æ–‡æ¡£å­—ç¬¦ä¸²
                        if method["docstring"]:
                            # å¦‚æœæ–‡æ¡£å­—ç¬¦ä¸²åªæœ‰ä¸€è¡Œï¼Œç”¨ç®€çŸ­æ ¼å¼æ˜¾ç¤º
                            docstring_lines = method["docstring"].split("\n")
                            if len(docstring_lines) == 1:
                                lines.append(f"  - *{method['docstring'].strip()}*")
                            else:
                                # å¤šè¡Œæ–‡æ¡£å­—ç¬¦ä¸²,ç”¨ä»£ç å—æ ¼å¼æ˜¾ç¤º
                                lines.append("  - **Docstring:**")
                                lines.append(f"  {FILE_CONTENT_BACKQUOTES}")
                                for doc_line in docstring_lines:
                                    lines.append(f"  {doc_line}")
                                lines.append(f"  {FILE_CONTENT_BACKQUOTES}")
                    lines.append("")

                # Properties
                if cls["properties"]:
                    lines.append(f"**Properties ({len(cls['properties'])}):**")
                    for prop in cls["properties"]:
                        return_str = f" -> {prop['return_type']}" if prop["return_type"] else ""
                        lines.append(f"- `@property {prop['name']}{return_str}`")
                    lines.append("")

                # ç±»å˜é‡
                if cls["class_variables"]:
                    lines.append(f"**Class Variables ({len(cls['class_variables'])}):**")
                    for var in cls["class_variables"]:
                        type_str = f": {var['type']}" if var["type"] else ""
                        value_str = f" = {var['value']}" if var.get("value") else ""
                        lines.append(f"- `{var['name']}{type_str}{value_str}`")
                    lines.append("")

        # é¡¶çº§å‡½æ•°
        if metadata.get("functions"):
            public_functions = [f for f in metadata["functions"] if f["is_public"]]
            if public_functions:
                lines.append(f"#### ğŸ”§ Public Functions ({len(public_functions)})\n")
                for func in public_functions:
                    params_str = self._format_parameters(func["parameters"])
                    return_str = f" -> {func['return_type']}" if func["return_type"] else ""
                    async_str = "async " if func["type"] == "async_function" else ""
                    
                    decorators_str = ""
                    if func["decorators"]:
                        decorators_str = " " + " ".join([f"`{d}`" for d in func["decorators"]])
                    
                    lines.append(f"- `{async_str}def {func['name']}({params_str}){return_str}`{decorators_str}")
                    lines.append(f"  - *Line: {func['lineno']}*")
                    
                    if func["docstring"]:
                        # å¦‚æœæ–‡æ¡£å­—ç¬¦ä¸²åªæœ‰ä¸€è¡Œï¼Œç”¨ç®€çŸ­æ ¼å¼æ˜¾ç¤º
                        docstring_lines = func["docstring"].split("\n")
                        if len(docstring_lines) == 1:
                            lines.append(f"  - *{func['docstring'].strip()}*")
                        else:
                            # å¤šè¡Œæ–‡æ¡£å­—ç¬¦ä¸²,ç”¨ä»£ç å—æ ¼å¼æ˜¾ç¤º
                            lines.append("  - **Docstring:**")
                            lines.append(f"  {FILE_CONTENT_BACKQUOTES}")
                            for doc_line in docstring_lines:
                                lines.append(f"  {doc_line}")
                            lines.append(f"  {FILE_CONTENT_BACKQUOTES}")
                    lines.append("")

        lines.append("\n---\n")
        return "\n".join(lines)

    def _format_parameters(self, parameters: list) -> str:
        """æ ¼å¼åŒ–å‡½æ•°å‚æ•°åˆ—è¡¨"""
        param_strs = []
        for param in parameters:
            param_str = param["name"]
            if param["type"]:
                param_str += f": {param['type']}"
            if param["default"]:
                param_str += f" = {param['default']}"
            param_strs.append(param_str)
        return ", ".join(param_strs)

    def merge_from_files_with_metadata(
        self,
        relative_file_name_list: typing.List[str],
        as_title: str,
        project_root: typing.Union[os.PathLike, str] = None,
        include_ast_metadata: bool = True,
        include_file_text: bool = True,
    ) -> "AiMdGenerator":
        """
        åˆå¹¶æ–‡ä»¶å†…å®¹åˆ° Markdownï¼Œå¯¹äº Python æ–‡ä»¶ä¼šé¢å¤–ç”Ÿæˆ AST å…ƒæ•°æ®
        
        Args:
            project_root: é¡¹ç›®æ ¹ç›®å½•
            relative_file_name_list: ç›¸å¯¹æ–‡ä»¶è·¯å¾„åˆ—è¡¨
            as_title: æ ‡é¢˜
            include_ast_metadata: æ˜¯å¦åŒ…å« AST å…ƒæ•°æ®ï¼ˆä»…å¯¹ .py æ–‡ä»¶ï¼‰
            include_file_text: æ˜¯å¦åŒ…å«å®Œæ•´æ–‡ä»¶æºç ï¼ˆFalse æ—¶åªæ˜¾ç¤ºå…ƒæ•°æ®ï¼‰
        """
        self._check_project_name()
        project_root =  project_root or self.project_root
        file_text_list = []
        project_root_path = NbPath(project_root).resolve()
        
        for relative_file_name in relative_file_name_list:
            file = (project_root_path / relative_file_name).resolve()
            if not file.exists():
                raise FileNotFoundError(f"File {file} not found.")
            if file.is_file() and file.is_text():
                relative_file_name_posix = file.relative_to(project_root_path).as_posix()
                try:
                    text = file.read_text()
                except Exception as e:
                    self.logger.error(f"Error reading file {file}: {e}")
                    text = ""
                
                file_text_list.append([file, relative_file_name_posix, file.suffix, text])
                self.logger.debug(f"need merged file: {file}")
            else:
                raise ValueError(f"File {file} is not a text file.")
        
        str_list = []
        if file_text_list:
            str_list.extend(self._generate_markdown_header(as_title, file_text_list))

        for file, relative_file_name_posix, suffix, text in file_text_list:
            # å¦‚æœä¸åŒ…å«æ–‡ä»¶å†…å®¹ï¼Œåªè¾“å‡ºå…ƒæ•°æ®ï¼ˆä»…å¯¹ Python æ–‡ä»¶ï¼‰
            if not include_file_text:
                if suffix == ".py" and include_ast_metadata:
                    # åªæ˜¾ç¤ºå…ƒæ•°æ®ï¼Œä¸æ˜¾ç¤ºæºç 
                    metadata = self._parse_python_file_ast(file)
                    metadata_md = self._format_py_metadata_as_markdown(metadata, relative_file_name_posix)
                    str_list.append(metadata_md)
                    str_list.append("\n")
                # é Python æ–‡ä»¶è·³è¿‡
                continue
            
            # æ­£å¸¸æµç¨‹ï¼šåŒ…å«æ–‡ä»¶å†…å®¹
            str_list.append(f"--- **start of file: {relative_file_name_posix}** (project: {self.project_name}) --- \n")
            
            # å¯¹äº Python æ–‡ä»¶ï¼Œæ·»åŠ  AST å…ƒæ•°æ®
            if suffix == ".py" and include_ast_metadata:
                metadata = self._parse_python_file_ast(file)
                metadata_md = self._format_py_metadata_as_markdown(metadata, relative_file_name_posix)
                str_list.append(metadata_md)
            
            # æ·»åŠ å®Œæ•´çš„æ–‡ä»¶å†…å®¹
            lang = self.suffix__lang_map.get(suffix, "text")
            str_list.append(f"{FILE_CONTENT_BACKQUOTES}{lang}\n{text}\n{FILE_CONTENT_BACKQUOTES}\n")

            str_list.append(f"--- **end of file: {relative_file_name_posix}** (project: {self.project_name}) --- \n")
            str_list.append("---\n\n")

        self.append_text('\n'.join(str_list))
        self.ensure_utf8_bom()
        return self

    def _analyze_file_dependencies(
        self, 
        file_list: typing.List[str], 
        project_root: typing.Union[os.PathLike, str] = None
    ) -> dict:
        """
        åˆ†æé¡¹ç›®æ–‡ä»¶ä¹‹é—´çš„ import ä¾èµ–å…³ç³»
        
        Args:
            file_list: ç›¸å¯¹æ–‡ä»¶è·¯å¾„åˆ—è¡¨
            project_root: é¡¹ç›®æ ¹ç›®å½•
            
        Returns:
            dict: {
                "internal_deps": {file: [ä¾èµ–çš„é¡¹ç›®å†…æ–‡ä»¶åˆ—è¡¨]},
                "external_deps": {file: [å¤–éƒ¨ä¾èµ–æ¨¡å—åˆ—è¡¨]},
                "reverse_deps": {file: [è¢«å“ªäº›æ–‡ä»¶ä¾èµ–]}
            }
        """
        project_root = project_root or self.project_root
        project_root_path = NbPath(project_root).resolve()
        
        # æ„å»ºé¡¹ç›®å†…æ¨¡å—ååˆ°æ–‡ä»¶è·¯å¾„çš„æ˜ å°„
        # ä¾‹å¦‚: "nb_ai_context.ai_md_generator" -> "nb_ai_context/ai_md_generator.py"
        module_to_file = {}
        file_to_module = {}
        
        for relative_file in file_list:
            if relative_file.endswith('.py'):
                # å°†æ–‡ä»¶è·¯å¾„è½¬æ¢ä¸ºæ¨¡å—å
                module_name = relative_file.replace('/', '.').replace('\\', '.')
                if module_name.endswith('.py'):
                    module_name = module_name[:-3]
                if module_name.endswith('.__init__'):
                    module_name = module_name[:-9]
                
                module_to_file[module_name] = relative_file
                file_to_module[relative_file] = module_name
                
                # ä¹Ÿæ·»åŠ å„çº§çˆ¶æ¨¡å—çš„æ˜ å°„
                parts = module_name.split('.')
                for i in range(1, len(parts)):
                    parent_module = '.'.join(parts[:i])
                    parent_file = '/'.join(parts[:i]) + '/__init__.py'
                    if parent_file in file_list:
                        module_to_file[parent_module] = parent_file
        
        internal_deps = {}  # é¡¹ç›®å†…éƒ¨ä¾èµ–
        external_deps = {}  # å¤–éƒ¨ä¾èµ–
        reverse_deps = {}   # åå‘ä¾èµ–ï¼ˆè¢«è°ä¾èµ–ï¼‰
        
        # åˆå§‹åŒ–
        for f in file_list:
            internal_deps[f] = []
            external_deps[f] = set()
            reverse_deps[f] = []
        
        # åˆ†ææ¯ä¸ª Python æ–‡ä»¶çš„ imports
        for relative_file in file_list:
            if not relative_file.endswith('.py'):
                continue
                
            file_path = project_root_path / relative_file
            if not file_path.exists():
                continue
                
            try:
                source_code = file_path.read_text(encoding='utf-8')
                if source_code.startswith('\ufeff'):
                    source_code = source_code[1:]
                tree = ast.parse(source_code)
            except Exception as e:
                self.logger.warning(f"æ— æ³•è§£ææ–‡ä»¶ {relative_file}: {e}")
                continue
            
            current_module = file_to_module.get(relative_file, '')
            # å¯¹äº __init__.py æ–‡ä»¶ï¼Œå®ƒæœ¬èº«å°±æ˜¯åŒ…ï¼Œcurrent_package åº”è¯¥ç­‰äº current_module
            # å¯¹äºæ™®é€š .py æ–‡ä»¶ï¼Œcurrent_package æ˜¯å…¶çˆ¶ç›®å½•å¯¹åº”çš„æ¨¡å—
            if relative_file.endswith('__init__.py'):
                current_package = current_module
            else:
                current_package = '.'.join(current_module.split('.')[:-1]) if '.' in current_module else ''
            
            for node in ast.walk(tree):
                if isinstance(node, ast.Import):
                    for alias in node.names:
                        module_name = alias.name
                        self._categorize_import(
                            module_name, relative_file, module_to_file,
                            internal_deps, external_deps, reverse_deps
                        )
                        
                elif isinstance(node, ast.ImportFrom):
                    module_name = node.module or ''
                    
                    # å¤„ç†ç›¸å¯¹å¯¼å…¥
                    if node.level > 0:  # ç›¸å¯¹å¯¼å…¥
                        if current_package:
                            # è®¡ç®—ç»å¯¹æ¨¡å—å
                            # level=1 è¡¨ç¤ºå½“å‰åŒ…ï¼Œlevel=2 è¡¨ç¤ºçˆ¶åŒ…ï¼Œä»¥æ­¤ç±»æ¨
                            package_parts = current_package.split('.')
                            # å›é€€ level-1 çº§ï¼ˆlevel=1 æ—¶ä¸å›é€€ï¼Œå°±æ˜¯å½“å‰åŒ…ï¼‰
                            levels_to_go_up = node.level - 1
                            if levels_to_go_up < len(package_parts):
                                base = '.'.join(package_parts[:len(package_parts) - levels_to_go_up])
                                if module_name:
                                    module_name = f"{base}.{module_name}"
                                else:
                                    module_name = base
                            else:
                                # ç›¸å¯¹å¯¼å…¥è¶…å‡ºäº†åŒ…çš„å±‚çº§ï¼Œä¿æŒåŸæ ·
                                if module_name:
                                    pass  # ä¿æŒ module_name ä¸å˜
                    
                    if module_name:
                        self._categorize_import(
                            module_name, relative_file, module_to_file,
                            internal_deps, external_deps, reverse_deps
                        )
        
        # è½¬æ¢ set ä¸º list å¹¶æ’åº
        for f in external_deps:
            external_deps[f] = sorted(list(external_deps[f]))
        
        return {
            "internal_deps": internal_deps,
            "external_deps": external_deps,
            "reverse_deps": reverse_deps,
            "module_to_file": module_to_file
        }
    
    def _categorize_import(
        self, 
        module_name: str, 
        current_file: str,
        module_to_file: dict,
        internal_deps: dict,
        external_deps: dict,
        reverse_deps: dict
    ):
        """å°† import åˆ†ç±»ä¸ºå†…éƒ¨ä¾èµ–æˆ–å¤–éƒ¨ä¾èµ–"""
        # æ£€æŸ¥æ˜¯å¦æ˜¯é¡¹ç›®å†…éƒ¨æ¨¡å—
        found_internal = False
        
        # å°è¯•åŒ¹é…å®Œæ•´æ¨¡å—åæˆ–å…¶å‰ç¼€
        parts = module_name.split('.')
        for i in range(len(parts), 0, -1):
            check_module = '.'.join(parts[:i])
            if check_module in module_to_file:
                dep_file = module_to_file[check_module]
                if dep_file != current_file and dep_file not in internal_deps[current_file]:
                    internal_deps[current_file].append(dep_file)
                    if dep_file in reverse_deps:
                        reverse_deps[dep_file].append(current_file)
                found_internal = True
                break
        
        if not found_internal:
            # å¤–éƒ¨ä¾èµ–ï¼Œåªè®°å½•é¡¶çº§æ¨¡å—å
            top_module = parts[0]
            external_deps[current_file].add(top_module)
    
    def _format_dependencies_as_markdown(self, deps_info: dict, file_list: typing.List[str]) -> str:
        """å°†ä¾èµ–å…³ç³»æ ¼å¼åŒ–ä¸º Markdown"""
        lines = []
        lines.append(f"\n## ğŸ”— {self.project_name} Some File Dependencies Analysis\n")
        lines.append("ä»¥ä¸‹æ˜¯é¡¹ç›®æ–‡ä»¶ä¹‹é—´çš„ä¾èµ–å…³ç³»ï¼Œå¸®åŠ© AI ç†è§£ä»£ç ç»“æ„ï¼š\n")
        
        internal_deps = deps_info["internal_deps"]
        external_deps = deps_info["external_deps"]
        reverse_deps = deps_info["reverse_deps"]
        
        # 1. ä¾èµ–å…³ç³»å›¾ï¼ˆæ–‡æœ¬å½¢å¼ï¼‰
        lines.append("### ğŸ“Š Internal Dependencies Graph\n")
        lines.append(f"{FILE_CONTENT_BACKQUOTES}")
        
        # æ‰¾å‡ºå…¥å£æ–‡ä»¶ï¼ˆæ²¡æœ‰è¢«å…¶ä»–æ–‡ä»¶ä¾èµ–çš„æ–‡ä»¶ï¼‰
        entry_files = [f for f in file_list if f.endswith('.py') and not reverse_deps.get(f, [])]
        if entry_files:
            lines.append("Entry Points (not imported by other project files):")
            for f in sorted(entry_files):
                lines.append(f"  â˜… {f}")
            lines.append("")
        
        # æ‰¾å‡ºæ ¸å¿ƒæ–‡ä»¶ï¼ˆè¢«å¤šä¸ªæ–‡ä»¶ä¾èµ–çš„æ–‡ä»¶ï¼‰
        core_files = [(f, len(reverse_deps.get(f, []))) for f in file_list if f.endswith('.py')]
        core_files = sorted(core_files, key=lambda x: x[1], reverse=True)
        core_files = [(f, count) for f, count in core_files if count > 0]
        
        if core_files:
            lines.append("Core Files (imported by other files, sorted by import count):")
            for f, count in core_files[:10]:  # åªæ˜¾ç¤ºå‰10ä¸ª
                lines.append(f"  â—† {f} (imported by {count} files)")
            lines.append("")
        
        lines.append(f"{FILE_CONTENT_BACKQUOTES}\n")
        
        # 2. è¯¦ç»†ä¾èµ–åˆ—è¡¨
        lines.append("### ğŸ“‹ Detailed Dependencies\n")
        
        py_files = sorted([f for f in file_list if f.endswith('.py')])
        
        for f in py_files:
            int_deps = internal_deps.get(f, [])
            rev_deps = reverse_deps.get(f, [])
            
            # åªæ˜¾ç¤ºæœ‰ä¾èµ–å…³ç³»çš„æ–‡ä»¶
            if int_deps or rev_deps:
                lines.append(f"#### `{f}`\n")
                
                if int_deps:
                    lines.append("**Imports from project:**")
                    for dep in sorted(int_deps):
                        lines.append(f"- `{dep}`")
                    lines.append("")
                
                if rev_deps:
                    lines.append("**Imported by:**")
                    for dep in sorted(rev_deps):
                        lines.append(f"- `{dep}`")
                    lines.append("")
        
        # 3. å¤–éƒ¨ä¾èµ–æ±‡æ€»
        all_external = set()
        for ext_list in external_deps.values():
            all_external.update(ext_list)
        
        if all_external:
            # è¿‡æ»¤æ‰æ ‡å‡†åº“æ¨¡å—ï¼ˆPython 3.7+ å®Œæ•´æ ‡å‡†åº“åˆ—è¡¨ï¼‰
            stdlib_modules = {
                # æ–‡æœ¬å¤„ç†
                'string', 'stringprep', 're', 'difflib', 'textwrap', 'unicodedata',
                # äºŒè¿›åˆ¶æ•°æ®
                'struct', 'codecs',
                # æ•°æ®ç±»å‹
                'datetime', 'zoneinfo', 'calendar', 'collections', 'heapq', 'bisect',
                'array', 'weakref', 'types', 'copy', 'pprint', 'reprlib', 'enum',
                'graphlib',
                # æ•°å­¦å’Œæ•°å­—
                'numbers', 'math', 'cmath', 'decimal', 'fractions', 'random', 'statistics',
                # å‡½æ•°å¼ç¼–ç¨‹
                'itertools', 'functools', 'operator',
                # æ–‡ä»¶å’Œç›®å½•
                'pathlib', 'os', 'io', 'time', 'argparse', 'getopt', 'logging',
                'getpass', 'curses', 'platform', 'errno', 'ctypes',
                # æ–‡ä»¶æ ¼å¼
                'csv', 'configparser', 'tomllib', 'netrc', 'plistlib',
                # åŠ å¯†
                'hashlib', 'hmac', 'secrets',
                # æ“ä½œç³»ç»ŸæœåŠ¡
                'os', 'io', 'time', 'argparse', 'getopt', 'logging', 'getpass',
                'curses', 'platform', 'errno', 'ctypes',
                # å¹¶å‘
                'threading', 'multiprocessing', 'concurrent', 'subprocess', 'sched',
                'queue', '_thread',
                # ç½‘ç»œå’Œè¿›ç¨‹é—´é€šä¿¡
                'asyncio', 'socket', 'ssl', 'select', 'selectors', 'signal',
                'mmap', 'asyncore', 'asynchat',
                # äº’è”ç½‘æ•°æ®å¤„ç†
                'email', 'json', 'mailbox', 'mimetypes', 'base64', 'binascii',
                'quopri', 'uu',
                # HTML å’Œ XML
                'html', 'xml',
                # äº’è”ç½‘åè®®
                'webbrowser', 'wsgiref', 'urllib', 'http', 'ftplib', 'poplib',
                'imaplib', 'smtplib', 'uuid', 'socketserver', 'xmlrpc', 'ipaddress',
                # å¤šåª’ä½“
                'wave', 'colorsys',
                # å›½é™…åŒ–
                'locale', 'gettext',
                # ç¨‹åºæ¡†æ¶
                'turtle', 'cmd', 'shlex',
                # å›¾å½¢ç•Œé¢
                'tkinter', 'idlelib',
                # å¼€å‘å·¥å…·
                'typing', 'pydoc', 'doctest', 'unittest', 'test', '2to3', 'lib2to3',
                # è°ƒè¯•å’Œæ€§èƒ½
                'bdb', 'faulthandler', 'pdb', 'profile', 'timeit', 'trace',
                'tracemalloc', 'cProfile',
                # è½¯ä»¶æ‰“åŒ…å’Œåˆ†å‘
                'distutils', 'ensurepip', 'venv', 'zipapp',
                # Python è¿è¡Œæ—¶
                'sys', 'sysconfig', 'builtins', 'warnings', 'dataclasses',
                'contextlib', 'abc', 'atexit', 'traceback', 'gc', 'inspect',
                'site',
                # è‡ªå®šä¹‰è§£é‡Šå™¨
                'code', 'codeop',
                # å¯¼å…¥ç³»ç»Ÿ
                'importlib', 'pkgutil', 'modulefinder', 'runpy', 'zipimport',
                # Python è¯­è¨€æœåŠ¡
                'ast', 'symtable', 'token', 'keyword', 'tokenize', 'tabnanny',
                'pyclbr', 'py_compile', 'compileall', 'dis', 'pickletools',
                # æ–‡ä»¶å½’æ¡£
                'zipfile', 'tarfile', 'gzip', 'bz2', 'lzma', 'shutil',
                # æŒä¹…åŒ–
                'pickle', 'copyreg', 'shelve', 'marshal', 'dbm', 'sqlite3',
                # æ–‡ä»¶é€šé…
                'glob', 'fnmatch', 'linecache', 'filecmp', 'fileinput', 'tempfile',
                # å…¶ä»–
                '__future__', 'rlcompleter', 'readline', 'posix', 'posixpath',
                'ntpath', 'genericpath', 'stat', 'grp', 'pwd', 'spwd', 'crypt',
                'termios', 'tty', 'pty', 'fcntl', 'resource', 'syslog',
                'aifc', 'sunau', 'chunk', 'imghdr', 'sndhdr', 'ossaudiodev',
                'typing_extensions',  # è™½ç„¶æ˜¯ç¬¬ä¸‰æ–¹ä½†é€šå¸¸è¢«è§†ä¸ºæ ‡å‡†æ‰©å±•
            }
            third_party = sorted([m for m in all_external if m not in stdlib_modules])
            
            if third_party:
                lines.append("### ğŸ“¦ Third-party Dependencies\n")
                lines.append("é¡¹ç›®ä½¿ç”¨çš„ç¬¬ä¸‰æ–¹åº“ï¼š\n")
                for m in third_party:
                    lines.append(f"- `{m}`")
                lines.append('- ......ä»¥åŠæ›´å¤šçš„ç¬¬ä¸‰æ–¹åº“......')
                lines.append("")
        
        lines.append("\n---\n")
        return "\n".join(lines)
    
    def add_file_dependencies(
        self,
        file_list: typing.List[str] = None,
        project_root: typing.Union[os.PathLike, str] = None,
    ) -> "AiMdGenerator":
        """
        åˆ†æå¹¶æ·»åŠ é¡¹ç›®æ–‡ä»¶ä¹‹é—´çš„ä¾èµ–å…³ç³»åˆ° markdown
        
        Args:
            file_list: è¦åˆ†æçš„æ–‡ä»¶åˆ—è¡¨ï¼ˆç›¸å¯¹è·¯å¾„ï¼‰ï¼Œå¦‚æœä¸º None åˆ™åˆ†ææ•´ä¸ªé¡¹ç›®
            project_root: é¡¹ç›®æ ¹ç›®å½•
            
        Example:
            >>> (
            ...     AiMdGenerator("output.md")
            ...     .set_project_propery("my_project", "/path/to/project")
            ...     .clear_text()
            ...     .add_project_summary(project_summary="...")
            ... )
        """
        self._check_project_name()
        project_root = project_root or self.project_root
        
        if file_list is None:
            # å¦‚æœæ²¡æœ‰æŒ‡å®šæ–‡ä»¶åˆ—è¡¨ï¼Œæ‰«ææ•´ä¸ªé¡¹ç›®çš„ .py æ–‡ä»¶
            project_root_path = NbPath(project_root).resolve()
            file_list = []
            for py_file in project_root_path.rglob("*.py"):
                # æ’é™¤éšè—ç›®å½•
                relative = py_file.relative_to(project_root_path)
                if not any(part.startswith('.') for part in relative.parts):
                    file_list.append(relative.as_posix())
        
        # åˆ†æä¾èµ–
        deps_info = self._analyze_file_dependencies(file_list, project_root)
        
        # æ ¼å¼åŒ–å¹¶æ·»åŠ åˆ° markdown
        deps_md = self._format_dependencies_as_markdown(deps_info, file_list)
        self.append_text(deps_md)
        
        return self
