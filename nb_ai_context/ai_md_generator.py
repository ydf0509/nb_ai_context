import typing
import os
import fnmatch
import ast

from nb_path import NbPath

class AiMdGenerator(NbPath):
    """
    An extremely powerful context generator born for AI collaboration.

    This class is designed to revolutionize how developers interact with Large Language
    Models (LLMs). It intelligently merges multiple project source files into a single,
    well-structured, and context-rich Markdown file, providing the AI with a perfect
    and comprehensive project snapshot.

    The benefits for large AI models are immense:
    1.  **Provides a God's-eye View**: Through a file manifest, clear file boundaries,
        and relative paths, the AI can easily construct the project's overall
        architecture and understand file dependencies and relationships, rather than
        fumbling in the dark.
    2.  **Ensures Information Integrity and Accuracy**: The AI receives complete,
        unabridged source file content, avoiding the chaos, omissions, or context
        loss caused by manual copy-pasting. This enables it to provide more precise
        analysis and suggestions.
    3.  **Enhances Security**: The built-in `use_gitignore` feature is a critical
        security barrier. It automatically ignores files containing sensitive
        information (like API keys or database passwords) such as `.env` or local
        configs, allowing you to share code without fear of accidental leaks.

    Its core methods, `merge_from_files` and `merge_from_dir`, offer extreme
    flexibility. Combined with the elegant chainable calls of `nb_path`, creating a
    high-quality AI context is transformed from a tedious, error-prone manual task
    into a single, delightful line of code.

    Example:
        >>> # Imagine you want an AI to review your entire project
        >>> project_name = "my_project"
        >>> project_summary = '''
        ... This is an excellent Python project that demonstrates best practices.
        ... It includes comprehensive documentation and well-structured code.
        ... '''
        >>> 
        >>> (
        ...     AiMdGenerator("project_context_for_ai.md")
        ...     .set_project_propery(project_name=project_name, project_root="/path/to/your/project")
        ...     .clear_text()  # Clear the old file
        ...     .add_project_summary(
        ...         project_summary=project_summary,
        ...         # Extract metadata (without full source) from core files first
        ...         most_core_source_code_file_list=[
        ...             "src/main.py",
        ...             "src/api.py",
        ...             "src/models.py",
        ...         ]
        ...     )
        ...     .auto_merge_from_python_project_some_files()  # Auto-include README, setup.py, etc.
        ...     .merge_from_dir(
        ...         relative_dir_name="src", # The main source code directory
        ...         as_title="Project Source Code",
        ...         use_gitignore=True,  # Automatically use .gitignore rules
        ...         should_include_suffixes=[".py", ".md"], # Only include specified file types
        ...         include_ast_metadata=True,  # Include AST metadata for Python files
        ...     )
        ...     .merge_from_dir(
        ...         relative_dir_name="tests", # The tests directory
        ...         as_title="Project Tests",
        ...         use_gitignore=True,
        ...         should_include_suffixes=[".py"],
        ...         excluded_dir_name_list=["tests/temp_files"],
        ...         include_ast_metadata=True,
        ...     )
        ... )
    """

    """cn description
    ä¸€ä¸ªæå…¶å¼ºå¤§çš„ã€ä¸º AI åä½œè€Œç”Ÿçš„ä¸Šä¸‹æ–‡ç”Ÿæˆå™¨ã€‚

    æ­¤ç±»æ—¨åœ¨å½»åº•æ”¹å˜å¼€å‘è€…ä¸å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„äº¤äº’æ–¹å¼ã€‚å®ƒèƒ½å¤Ÿæ™ºèƒ½åœ°å°†å¤šä¸ªé¡¹ç›®æºæ–‡ä»¶
    åˆå¹¶æˆä¸€ä¸ªç»“æ„æ¸…æ™°ã€ä¸Šä¸‹æ–‡ä¸°å¯Œçš„å•ä¸€ Markdown æ–‡ä»¶ï¼Œä»è€Œä¸º AI æä¾›ä¸€ä¸ªå®Œç¾ã€å…¨é¢çš„é¡¹ç›®å¿«ç…§ã€‚

    å¯¹ AI å¤§æ¨¡å‹çš„å¥½å¤„æ˜¯å·¨å¤§çš„ï¼š
    1.  **æä¾›ä¸Šå¸è§†è§’**ï¼šé€šè¿‡æ–‡ä»¶æ¸…å•ã€æ¸…æ™°çš„æ–‡ä»¶è¾¹ç•Œå’Œç›¸å¯¹è·¯å¾„ï¼ŒAI èƒ½å¤Ÿè½»æ¾æ„å»ºå‡ºé¡¹ç›®çš„
        æ•´ä½“æ¶æ„ï¼Œç†è§£æ–‡ä»¶é—´çš„ä¾èµ–å’Œå¼•ç”¨å…³ç³»ï¼Œè€Œä¸æ˜¯ç›²äººæ‘¸è±¡ã€‚
    2.  **ç¡®ä¿ä¿¡æ¯çš„å®Œæ•´ä¸å‡†ç¡®**ï¼šAI å¾—åˆ°çš„æ˜¯æœªç»åˆ å‡çš„ã€å®Œæ•´çš„æºæ–‡ä»¶å†…å®¹ï¼Œé¿å…äº†å› æ‰‹åŠ¨
        å¤åˆ¶ç²˜è´´å¯¼è‡´çš„æ ¼å¼æ··ä¹±ã€å†…å®¹é—æ¼æˆ–ä¸Šä¸‹æ–‡ç¼ºå¤±ï¼Œä»è€Œèƒ½ç»™å‡ºæ›´ç²¾å‡†çš„åˆ†æå’Œå»ºè®®ã€‚
    3.  **æå‡å®‰å…¨æ€§**ï¼šå†…ç½®çš„ `use_gitignore` åŠŸèƒ½æ˜¯ä¸€é“å…³é”®çš„å®‰å…¨å±éšœã€‚å®ƒèƒ½è‡ªåŠ¨å¿½ç•¥
        `.env`ã€æœ¬åœ°é…ç½®ç­‰åŒ…å«æ•æ„Ÿä¿¡æ¯ï¼ˆå¦‚ API å¯†é’¥ã€æ•°æ®åº“å¯†ç ï¼‰çš„æ–‡ä»¶ï¼Œè®©ä½ åœ¨åˆ†äº«ä»£ç 
        æ—¶æ— éœ€æ‹…å¿ƒæ„å¤–æ³„éœ²ç§˜å¯†ã€‚

    å…¶æ ¸å¿ƒæ–¹æ³• `merge_from_files` å’Œ `merge_from_dir` æä¾›äº†æé«˜çš„çµæ´»æ€§ï¼Œç»“åˆ `nb_path`
    ä¼˜é›…çš„é“¾å¼è°ƒç”¨ï¼Œä½¿å¾—åˆ›å»ºä¸€ä¸ªé«˜è´¨é‡çš„ AI ä¸Šä¸‹æ–‡ä»ç¹çã€æ˜“é”™çš„æ‰‹å·¥åŠ³åŠ¨ï¼Œå˜æˆäº†ä¸€è¡Œ
    èµå¿ƒæ‚¦ç›®çš„ä»£ç ã€‚

    """

    suffix__lang_map = {
        ".py": "python",
        ".md": "markdown",
        ".txt": "text",
        ".json": "json",
        ".yaml": "yaml",
        ".yml": "yaml",
        ".xml": "xml",
        ".html": "html",
        ".css": "css",
        ".js": "javascript",
        ".ts": "typescript",
        ".jsx": "javascript",
        ".tsx": "typescript",
        ".vue": "vue",
        ".php": "php",
        ".java": "java",
        ".c": "c",
        ".cpp": "cpp",
        ".h": "h",
        ".hpp": "hpp",
        ".cs": "csharp",
        ".vb": "vb",
        ".sql": "sql",
        ".bat": "batch",
        ".sh": "shell",
        ".ps1": "powershell",
        ".psm1": "powershell",
        ".psd1": "powershell",
        ".pssc": "powershell",
        ".psscx": "powershell",
    }

    def set_project_propery(self, project_name: str, project_root: typing.Union[os.PathLike, str] ) -> "AiMdGenerator":
        """Sets the project name for the current markdown file."""
        self.project_name = project_name
        self.project_root = project_root
        return self
    
    def _check_project_name(self) -> "AiMdGenerator":
        """Checks if the project name is set."""
        if not hasattr(self, 'project_name'):
            raise ValueError("Project name is not set. Please call set_project_name() first.")
        return self

    def add_project_summary(
        self, 
        project_summary: str, 
        most_core_source_code_file_list: typing.List[str] = None,
        project_root: typing.Union[os.PathLike, str] = None,
    ) -> "AiMdGenerator":
        """
        Adds a project summary to the current markdown file.
        
        Args:
            project_summary: é¡¹ç›®æ¦‚è¿°æ–‡æœ¬
            project_root: é¡¹ç›®æ ¹ç›®å½•ï¼ˆå¦‚æœæä¾›äº† most_core_source_code_file_listï¼‰
            most_core_source_code_file_list: æœ€æ ¸å¿ƒçš„æºç æ–‡ä»¶åˆ—è¡¨ï¼ˆç›¸å¯¹è·¯å¾„ï¼‰
                                             åªæå–è¿™äº›æ–‡ä»¶çš„ AST å…ƒæ•°æ®ï¼Œä¸åŒ…å«å®Œæ•´æºç 
        
        Example:
            >>> (
            ...     AiMdGenerator("output.md")
            ...     .set_project_name("my_project")
            ...     .clear_text()
            ...     .add_project_summary(
            ...         project_summary="è¿™æ˜¯ä¸€ä¸ªä¼˜ç§€çš„é¡¹ç›®...",
            ...         project_root="/path/to/project",
            ...         most_core_source_code_file_list=["src/main.py", "src/api.py"],
            ...     )
            ... )
        """
        self._check_project_name()
        project_root =  project_root or self.project_root 
        str_list = [f"# markdown content namespace: {self.project_name} project summary \n\n"]
        str_list.append(project_summary)
        # str_list.append("\n---\n\n")
        
        # å¦‚æœæä¾›äº†æ ¸å¿ƒæ–‡ä»¶åˆ—è¡¨ï¼Œæå–å®ƒä»¬çš„å…ƒæ•°æ®ï¼ˆä¸åŒ…å«æºç ï¼‰
        if most_core_source_code_file_list and project_root:
            # str_list.append("\n---\n\n")
            str_list.append("\n## ğŸ“‹ Core Source Files Metadata (Entry Points)\n\n")
            str_list.append("ä»¥ä¸‹æ˜¯é¡¹ç›®æœ€æ ¸å¿ƒçš„å…¥å£æ–‡ä»¶çš„ç»“æ„åŒ–å…ƒæ•°æ®ï¼Œå¸®åŠ©å¿«é€Ÿç†è§£é¡¹ç›®æ¶æ„ï¼š\n\n")
            most_core_source_code_file_list_str = ''
            for relative_file_name in most_core_source_code_file_list:
                most_core_source_code_file_list_str += f"- `{relative_file_name}`\n"
            str_list.append(f'\n### the project {self.project_name} most core source code files as follows: \n{most_core_source_code_file_list_str}')
            
            
            project_root_path = NbPath(project_root).resolve()
            
            for relative_file_name in most_core_source_code_file_list:
                file = (project_root_path / relative_file_name).resolve()
                if not file.exists():
                    raise FileNotFoundError(f"File {file} not found.")

                if file.is_file() and file.is_text() and file.suffix == ".py":
                    relative_file_name_posix = file.relative_to(project_root_path).as_posix()
                    
                    self.logger.info(f"æå–æ ¸å¿ƒæ–‡ä»¶å…ƒæ•°æ®ï¼ˆæ— æºç ï¼‰: {relative_file_name_posix}")
                    
                    # åªæå–å…ƒæ•°æ®ï¼Œä¸åŒ…å«æºç 
                    metadata = self._parse_python_file_ast(file)
                    metadata_md = self._format_py_metadata_as_markdown(metadata, relative_file_name_posix)
                    str_list.append(metadata_md)
                    str_list.append("\n")
        
        self.append_text('\n'.join(str_list))
        return self

    def _generate_markdown_header(self, as_title: str, file_text_list: list) -> list:
        """ç”ŸæˆåŒ…å«æ–‡ä»¶æ ‘å’Œæ–‡ä»¶åˆ—è¡¨çš„ Markdown å¤´éƒ¨"""
        str_list = [f"# markdown content namespace: {as_title} \n\n"]

        # 1. ç”Ÿæˆæ–‡ä»¶æ ‘
        str_list.append("## File Tree\n\n")
        str_list.append("```\n")
        tree = {}
        sorted_paths = sorted([item[1] for item in file_text_list])
        for path in sorted_paths:
            parts = path.split('/')
            current_level = tree
            for part in parts:
                if part not in current_level:
                    current_level[part] = {}
                current_level = current_level[part]

        def format_tree(node, prefix=""):
            lines = []
            entries = sorted(node.keys())
            for i, entry in enumerate(entries):
                connector = "â”œâ”€â”€ " if i < len(entries) - 1 else "â””â”€â”€ "
                lines.append(f"{prefix}{connector}{entry}")
                if node[entry]:
                    extension = "â”‚   " if i < len(entries) - 1 else "    "
                    lines.extend(format_tree(node[entry], prefix + extension))
            return lines

        str_list.extend(format_tree(tree))
        str_list.append("\n```\n\n---\n\n")

        # 2. ç”Ÿæˆæ–‡ä»¶åˆ—è¡¨
        str_list.append("## Included Files\n\n")
        for _, relative_file_name_posix, _, _ in file_text_list:
            str_list.append(f"- `{relative_file_name_posix}`\n")
        str_list.append("\n---\n\n")

        return str_list

    def auto_merge_from_python_project_some_files(self, project_root: typing.Union[os.PathLike, str] = None) -> 'AiMdGenerator':
        """è‡ªåŠ¨åˆå¹¶é¡¹ç›®æ ¹ç›®å½•ä¸‹çš„ readme.md æˆ–è€…ReADME.md ä»¥åŠsetup.py å’Œ pyproject.toml ï¼Œå¦‚æœæœ‰å°±æ·»åŠ """
        self._check_project_name()
        project_root =  project_root or self.project_root
        file_merge_list = []
        
        # å®šä¹‰è¦æŸ¥æ‰¾çš„æ ¹ç›®å½•æ–‡ä»¶
        root_files_to_check = [
            "README.md",
            # "readme.md",
            "setup.py",
            "pyproject.toml"
        ]
        
        # æ£€æŸ¥æ¯ä¸ªæ–‡ä»¶æ˜¯å¦å­˜åœ¨ï¼Œå¦‚æœå­˜åœ¨åˆ™æ·»åŠ åˆ°åˆå¹¶åˆ—è¡¨ä¸­
        project_root_path = NbPath(project_root).resolve()
        for filename in root_files_to_check:
            file_path = project_root_path / filename
            if file_path.is_file() and file_path.is_text():
                file_merge_list.append(filename)
                
        self.merge_from_files(file_merge_list, f"{self.project_name} Project Root Dir Some Files",project_root, )
        return self

    def merge_from_files(
        self,
        relative_file_name_list: typing.List[str],
        as_title: str,
        project_root: typing.Union[os.PathLike, str] = None,
    ) -> "AiMdGenerator":
        """Merges the content of the given files into the current markdown file.
        the current markdown file will be used to upload to ai model for code review and learning.
        """
        self._check_project_name()
        project_root =  project_root or self.project_root
        file_text_list = []
        project_root_path = NbPath(project_root).resolve()
        for relative_file_name in relative_file_name_list:
            file = (project_root_path / relative_file_name).resolve()
            if not file.exists():
                raise FileNotFoundError(f"File {file} not found.")
            if file.is_file() and file.is_text():
                relative_file_name_posix = file.relative_to(
                    project_root_path
                ).as_posix()
                try:
                    text = file.read_text()
                except Exception as e:
                    self.logger.error(f"Error reading file {file}: {e}")
                    text = ""
                file_text_list.append(
                    [file, relative_file_name_posix, file.suffix, text]
                )
                self.logger.debug(f"need merged file: {file}")
            else:
                raise ValueError(f"File {file} is not a text file.")
        str_list = []
        if file_text_list:
            # è°ƒç”¨æ–°å‡½æ•°ç”Ÿæˆå¤´éƒ¨
            str_list.extend(self._generate_markdown_header(as_title, file_text_list))


        for file, relative_file_name_posix, suffix, text in file_text_list:
            # 2. Remove the debug print statement.
            # print(f'file: {file}, relative_file_name_posix: {relative_file_name_posix}, suffix: {suffix}, text: {text}')
            str_list.append(f"--- **start of file: {relative_file_name_posix}** --- \n")
            # 3. Handle .md files separately to ensure their content is rendered correctly.
            #    Other file types are wrapped in code blocks.
            if suffix == ".md":
                str_list.append(text + "\n")
            else:
                lang = self.suffix__lang_map.get(suffix, "text")
                str_list.append(f"``{lang}\n{text}\n```\n")

            str_list.append(f"--- **end of file: {relative_file_name_posix}** --- \n")
            str_list.append("---\n\n")

        # with self.open(mode="a", encoding="utf-8") as f:
        #     f.write("\n".join(str_list))
        self.append_text('\n'.join(str_list))
        self.ensure_utf8_bom()
        return self
        
        
    def merge_from_dir(
        self,
        relative_dir_name: str,
        as_title: str,
        project_root: typing.Union[os.PathLike, str] = None,
        should_include_suffixes: typing.List[str] = [],
        excluded_dir_name_list: typing.List[str] = [],
        excluded_file_name_list: typing.List[str] = [],
        use_gitignore: bool = True,
        dry_run: bool = False,
        include_ast_metadata: bool = True,
    ) -> "AiMdGenerator":
        """Merges the content of the given directory into the current file."""
        project_root =  project_root or self.project_root
        project_root_path = NbPath(project_root).resolve()
        target_dir_path = (project_root_path / relative_dir_name).resolve()
        if not target_dir_path.exists():
            raise FileNotFoundError(f"Directory {target_dir_path} not found.")

        # Use sets for efficient lookups
        excluded_dir_paths = {
            (project_root_path / d).resolve() for d in excluded_dir_name_list
        }
        excluded_file_paths = {
            (project_root_path / f).resolve() for f in excluded_file_name_list
        }

        ignore_patterns = []
        if use_gitignore:
            try:
                gitignore_path = project_root_path.find_git_root() / ".gitignore"
                if gitignore_path.is_file():
                    self.logger.debug(f"Using .gitignore rules from: {gitignore_path}")
                    with open(gitignore_path, "r", encoding="utf-8") as f:
                        for line in f:
                            line = line.strip()
                            if line and not line.startswith("#"):
                                # Gitignore patterns always use forward slashes.
                                # We will compare against the posix version of the relative path
                                # for cross-platform reliability.
                                ignore_patterns.append(line)
            except FileNotFoundError:
                self.logger.warning("use_gitignore is True, but no .git/ or .gitignore file found.")

        relative_paths_to_include = []
        for path_obj in target_dir_path.rglob("*"):
            # Automatically exclude directories starting with a dot at the project root
            try:
                first_part = path_obj.relative_to(project_root_path).parts[0]
                if first_part.startswith('.'):
                    continue
            except (ValueError, IndexError):
                continue
            # Check if the path is within any of the excluded directories
            is_in_excluded_dir = any(
                path_obj == excluded_dir or excluded_dir in path_obj.parents
                for excluded_dir in excluded_dir_paths
            )
            if is_in_excluded_dir:
                continue

            # Check if the path matches any gitignore patterns.
            # Convert the relative path to a posix-style string for reliable matching.
            relative_to_root = path_obj.relative_to(project_root_path)
            relative_posix_path = relative_to_root.as_posix()
            # Use fnmatch for robust gitignore-style pattern matching.
            is_ignored = False
            for p in ignore_patterns:
                # If a pattern does not contain a slash, it matches in any directory.
                # e.g., 'test_git_ignore1.py' should match 'nb_path/example_dir/test_git_ignore1.py'
                if '/' not in p.strip('/'):
                    p_glob = f"**/{p.strip('/')}"
                else:
                    p_glob = p
                if fnmatch.fnmatch(relative_posix_path, p_glob) or fnmatch.fnmatch(relative_posix_path, p):
                    is_ignored = True
                    break
            if is_ignored:
                self.logger.debug(f"Ignoring {relative_to_root} due to .gitignore rule.")
                continue

            if path_obj.is_file():
                # Check if the file itself is excluded
                if path_obj.resolve() in excluded_file_paths:
                    continue
                # Check if the file is a text file
                if not path_obj.is_text():
                    continue
                # Check if the suffix is in the inclusion list (if the list is not empty)
                if (
                    should_include_suffixes
                    and path_obj.suffix not in should_include_suffixes
                ):
                    continue
                relative_paths_to_include.append(
                    path_obj.relative_to(project_root_path).as_posix()
                )

        if dry_run:
            print("\n--- [DRY RUN] AiMdGenerator Execution Plan ---")
            print(f"\nâœ… {len(relative_paths_to_include)} files would be INCLUDED in '{self.name}':")
            for p in sorted(relative_paths_to_include):
                print(f"  - {p}")
            print("\n--- End of DRY RUN ---")
            return self
        else:
            # ä½¿ç”¨å¸¦å…ƒæ•°æ®çš„æ–¹æ³•
            return self.merge_from_files_with_metadata(
                 
                relative_paths_to_include, 
                as_title,
                project_root=project_root,
                include_ast_metadata=include_ast_metadata
            )

    def _ast_to_source(self, node) -> str:
        """å°† AST èŠ‚ç‚¹è½¬æ¢ä¸ºæºä»£ç å­—ç¬¦ä¸²ï¼Œå…¼å®¹ Python 3.7+"""
        if node is None:
            return ""
        try:
            # Python 3.9+ æ”¯æŒ ast.unparse
            if hasattr(ast, 'unparse'):
                return ast.unparse(node)
            else:
                # Python 3.7/3.8 çš„å›é€€æ–¹æ¡ˆ
                # å°è¯•ä½¿ç”¨ astor
                try:
                    import astor
                    return astor.to_source(node).strip()
                except ImportError:
                    pass
                
                # ç®€å•çš„æ‰‹å·¥å¤„ç†å¸¸è§æƒ…å†µ
                if isinstance(node, ast.Name):
                    return node.id
                elif isinstance(node, ast.Constant):
                    return repr(node.value)
                elif isinstance(node, ast.Attribute):
                    value = self._ast_to_source(node.value)
                    return f"{value}.{node.attr}"
                elif isinstance(node, ast.Subscript):
                    value = self._ast_to_source(node.value)
                    slice_val = self._ast_to_source(node.slice)
                    return f"{value}[{slice_val}]"
                elif isinstance(node, (ast.List, ast.Tuple)):
                    elts = [self._ast_to_source(e) for e in node.elts]
                    if isinstance(node, ast.List):
                        return f"[{', '.join(elts)}]"
                    else:
                        return f"({', '.join(elts)})"
                else:
                    # å¯¹äºå¤æ‚ç±»å‹ï¼Œè¿”å›ç±»å‹åç§°
                    return node.__class__.__name__
        except Exception:
            return ""

    def _parse_type_annotation(self, annotation) -> str:
        """è§£æç±»å‹æ³¨è§£ï¼Œè¿”å›å­—ç¬¦ä¸²è¡¨ç¤º"""
        return self._ast_to_source(annotation)

    def _extract_function_metadata(self, node: typing.Union[ast.FunctionDef, ast.AsyncFunctionDef]) -> dict:
        """æå–å‡½æ•°/æ–¹æ³•çš„å…ƒæ•°æ®"""
        metadata = {
            "name": node.name,
            "type": "async_function" if isinstance(node, ast.AsyncFunctionDef) else "function",
            "lineno": node.lineno,
            "docstring": ast.get_docstring(node) or "",
            "parameters": [],
            "return_type": self._parse_type_annotation(node.returns),
            "decorators": [self._ast_to_source(dec) for dec in node.decorator_list],
            "is_public": not node.name.startswith("_"),
        }

        # æå–å‚æ•°ä¿¡æ¯
        for arg in node.args.args:
            param_info = {
                "name": arg.arg,
                "type": self._parse_type_annotation(arg.annotation),
                "default": None,
            }
            metadata["parameters"].append(param_info)

        # å¤„ç†é»˜è®¤å‚æ•°
        defaults = node.args.defaults
        if defaults:
            # é»˜è®¤å€¼ä»åå¾€å‰å¯¹åº”å‚æ•°
            num_defaults = len(defaults)
            for i, default in enumerate(defaults):
                param_idx = len(metadata["parameters"]) - num_defaults + i
                if param_idx >= 0:
                    try:
                        metadata["parameters"][param_idx]["default"] = self._ast_to_source(default)
                    except Exception:
                        metadata["parameters"][param_idx]["default"] = "<complex_default>"

        # å¤„ç† *args å’Œ **kwargs
        if node.args.vararg:
            metadata["parameters"].append({
                "name": f"*{node.args.vararg.arg}",
                "type": self._parse_type_annotation(node.args.vararg.annotation),
                "default": None,
            })
        if node.args.kwarg:
            metadata["parameters"].append({
                "name": f"**{node.args.kwarg.arg}",
                "type": self._parse_type_annotation(node.args.kwarg.annotation),
                "default": None,
            })

        return metadata

    def _extract_class_metadata(self, node: ast.ClassDef) -> dict:
        """æå–ç±»çš„å…ƒæ•°æ®"""
        metadata = {
            "name": node.name,
            "type": "class",
            "lineno": node.lineno,
            "docstring": ast.get_docstring(node) or "",
            "bases": [self._ast_to_source(base) for base in node.bases],
            "decorators": [self._ast_to_source(dec) for dec in node.decorator_list],
            "methods": [],
            "properties": [],
            "class_variables": [],
            "is_public": not node.name.startswith("_"),
        }

        # éå†ç±»çš„æˆå‘˜
        for item in node.body:
            if isinstance(item, (ast.FunctionDef, ast.AsyncFunctionDef)):
                method_info = self._extract_function_metadata(item)
                
                # æ£€æŸ¥æ˜¯å¦æ˜¯ property
                is_property = any("property" in dec for dec in method_info["decorators"])
                if is_property:
                    metadata["properties"].append(method_info)
                else:
                    metadata["methods"].append(method_info)
            
            elif isinstance(item, ast.AnnAssign) and isinstance(item.target, ast.Name):
                # ç±»å˜é‡ï¼ˆå¸¦ç±»å‹æ³¨è§£ï¼‰
                value_str = ""
                if item.value:
                    try:
                        value_str = self._ast_to_source(item.value)
                        # é™åˆ¶å€¼çš„é•¿åº¦
                        if len(value_str) > 50:
                            value_str = value_str[:50] + "..."
                    except Exception:
                        value_str = "<value>"
                
                metadata["class_variables"].append({
                    "name": item.target.id,
                    "type": self._parse_type_annotation(item.annotation),
                    "value": value_str,
                    "lineno": item.lineno,
                })
            elif isinstance(item, ast.Assign):
                # ç±»å˜é‡ï¼ˆæ— ç±»å‹æ³¨è§£ï¼‰
                for target in item.targets:
                    if isinstance(target, ast.Name):
                        # æå–å€¼
                        value_str = ""
                        if item.value:
                            try:
                                value_str = self._ast_to_source(item.value)
                                # é™åˆ¶å€¼çš„é•¿åº¦
                                if len(value_str) > 50:
                                    value_str = value_str[:50] + "..."
                            except Exception:
                                value_str = "<value>"
                        
                        metadata["class_variables"].append({
                            "name": target.id,
                            "type": "",
                            "value": value_str,
                            "lineno": item.lineno,
                        })

        return metadata

    def _parse_python_file_ast(self, file_path: NbPath) -> dict:
        """è§£æ Python æ–‡ä»¶çš„ ASTï¼Œæå–æ‰€æœ‰å…ƒæ•°æ®"""
        try:
            source_code = file_path.read_text(encoding="utf-8")
            # ç§»é™¤ BOM (Byte Order Mark) å­—ç¬¦ï¼Œå¦‚æœå­˜åœ¨çš„è¯
            # BOM æ˜¯ U+FEFFï¼Œåœ¨ UTF-8 ç¼–ç ä¸­æ˜¯ \ufeff
            if source_code.startswith('\ufeff'):
                source_code = source_code[1:]
                self.logger.debug(f"Removed BOM from file: {file_path}")
            tree = ast.parse(source_code, filename=str(file_path))
        except Exception as e:
            self.logger.error(f"Failed to parse Python file {file_path}: {e}")
            return {
                "error": str(e),
                "classes": [],
                "functions": [],
                "imports": [],
                "module_docstring": "",
            }

        metadata = {
            "file": str(file_path),
            "module_docstring": ast.get_docstring(tree) or "",
            "classes": [],
            "functions": [],
            "imports": [],
            "constants": [],
        }

        # éå†æ¨¡å—çº§åˆ«çš„èŠ‚ç‚¹
        for node in ast.walk(tree):
            # åªå¤„ç†æ¨¡å—çº§åˆ«çš„å®šä¹‰ï¼ˆé€šè¿‡æ£€æŸ¥çˆ¶èŠ‚ç‚¹ï¼‰
            if isinstance(node, ast.ClassDef):
                # æ£€æŸ¥æ˜¯å¦æ˜¯é¡¶çº§ç±»ï¼ˆä¸åœ¨å…¶ä»–ç±»å†…éƒ¨ï¼‰
                parent = None
                for potential_parent in ast.walk(tree):
                    if isinstance(potential_parent, ast.ClassDef) and node in ast.walk(potential_parent) and node != potential_parent:
                        parent = potential_parent
                        break
                if parent is None:  # é¡¶çº§ç±»
                    metadata["classes"].append(self._extract_class_metadata(node))

            elif isinstance(node, (ast.FunctionDef, ast.AsyncFunctionDef)):
                # æ£€æŸ¥æ˜¯å¦æ˜¯é¡¶çº§å‡½æ•°ï¼ˆä¸åœ¨ç±»å†…éƒ¨ï¼‰
                parent_class = None
                for potential_parent in ast.walk(tree):
                    if isinstance(potential_parent, ast.ClassDef) and node in ast.walk(potential_parent):
                        parent_class = potential_parent
                        break
                if parent_class is None:  # é¡¶çº§å‡½æ•°
                    metadata["functions"].append(self._extract_function_metadata(node))

            elif isinstance(node, (ast.Import, ast.ImportFrom)):
                if isinstance(node, ast.Import):
                    for alias in node.names:
                        metadata["imports"].append({
                            "type": "import",
                            "module": alias.name,
                            "alias": alias.asname,
                            "lineno": node.lineno,
                        })
                else:  # ImportFrom
                    module = node.module or ""
                    for alias in node.names:
                        metadata["imports"].append({
                            "type": "from_import",
                            "module": module,
                            "name": alias.name,
                            "alias": alias.asname,
                            "lineno": node.lineno,
                        })

        return metadata

    def _format_py_metadata_as_markdown(self, metadata: dict, relative_file_name: str) -> str:
        """å°† Python æ–‡ä»¶å…ƒæ•°æ®æ ¼å¼åŒ–ä¸º Markdown"""
        lines = []
        lines.append(f"\n### ğŸ“„ Python File Metadata: `{relative_file_name}`\n")

        # æ¨¡å—æ–‡æ¡£å­—ç¬¦ä¸²
        if metadata.get("module_docstring"):
            lines.append("#### ğŸ“ Module Docstring\n")
            lines.append("```")
            lines.append(metadata["module_docstring"])
            lines.append("```\n")

        # å¯¼å…¥ä¿¡æ¯
        if metadata.get("imports"):
            lines.append("#### ğŸ“¦ Imports\n")
            for imp in metadata["imports"]:  # æ˜¾ç¤ºæ‰€æœ‰ importsï¼Œä¸å†é™åˆ¶æ•°é‡
                if imp["type"] == "import":
                    alias_str = f" as {imp['alias']}" if imp['alias'] else ""
                    lines.append(f"- `import {imp['module']}{alias_str}`")
                else:
                    alias_str = f" as {imp['alias']}" if imp['alias'] else ""
                    lines.append(f"- `from {imp['module']} import {imp['name']}{alias_str}`")
            lines.append("")

        # ç±»ä¿¡æ¯
        if metadata.get("classes"):
            lines.append(f"#### ğŸ›ï¸ Classes ({len(metadata['classes'])})\n")
            for cls in metadata["classes"]:
                # åªæ˜¾ç¤ºå…¬æœ‰ç±»æˆ–æ‰€æœ‰ç±»ï¼ˆæ ¹æ®éœ€è¦ï¼‰
                class_header = f"##### ğŸ“Œ `class {cls['name']}"
                if cls["bases"]:
                    class_header += f"({', '.join(cls['bases'])})"
                class_header += "`"
                lines.append(class_header)
                lines.append(f"*Line: {cls['lineno']}*\n")
                
                if cls["docstring"]:
                    # æ˜¾ç¤ºå®Œæ•´çš„ç±»æ–‡æ¡£å­—ç¬¦ä¸²
                    docstring_lines = cls["docstring"].split("\n")
                    lines.append("**Docstring:**")
                    lines.append("```")
                    lines.extend(docstring_lines)
                    lines.append("```\n")

                # é¦–å…ˆå•ç‹¬æ˜¾ç¤º __init__ æ–¹æ³•ï¼ˆéå¸¸é‡è¦ï¼‰
                init_method = None
                for method in cls["methods"]:
                    if method["name"] == "__init__":
                        init_method = method
                        break
                
                if init_method:
                    lines.append("**ğŸ”§ Constructor (`__init__`):**")
                    params_str = self._format_parameters(init_method["parameters"])
                    lines.append(f"- `def __init__({params_str})`")
                    
                    # æ˜¾ç¤º __init__ çš„å®Œæ•´æ–‡æ¡£å­—ç¬¦ä¸²
                    if init_method["docstring"]:
                        lines.append("  - **Docstring:**")
                        lines.append("  ```")
                        for doc_line in init_method["docstring"].split("\n"):
                            lines.append(f"  {doc_line}")
                        lines.append("  ```")
                    
                    # æ˜¾ç¤ºæ¯ä¸ªå‚æ•°çš„è¯¦ç»†ä¿¡æ¯
                    if init_method["parameters"]:
                        lines.append("  - **Parameters:**")
                        for param in init_method["parameters"]:
                            param_name = param["name"]
                            param_type = f": {param['type']}" if param["type"] else ""
                            param_default = f" = {param['default']}" if param["default"] else ""
                            lines.append(f"    - `{param_name}{param_type}{param_default}`")
                    lines.append("")

                # å…¬æœ‰æ–¹æ³•ï¼ˆæ’é™¤ __init__ï¼‰
                public_methods = [m for m in cls["methods"] if m["is_public"] and m["name"] != "__init__"]
                if public_methods:
                    lines.append(f"**Public Methods ({len(public_methods)}):**")
                    for method in public_methods:
                        params_str = self._format_parameters(method["parameters"])
                        return_str = f" -> {method['return_type']}" if method["return_type"] else ""
                        async_str = "async " if method["type"] == "async_function" else ""
                        
                        decorators_str = ""
                        if method["decorators"]:
                            decorators_str = " " + " ".join([f"`{d}`" for d in method["decorators"]])
                        
                        lines.append(f"- `{async_str}def {method['name']}({params_str}){return_str}`{decorators_str}")
                        
                        # æ˜¾ç¤ºå®Œæ•´çš„æ–‡æ¡£å­—ç¬¦ä¸²
                        if method["docstring"]:
                            # å¦‚æœæ–‡æ¡£å­—ç¬¦ä¸²åªæœ‰ä¸€è¡Œï¼Œç”¨ç®€çŸ­æ ¼å¼æ˜¾ç¤º
                            docstring_lines = method["docstring"].split("\n")
                            if len(docstring_lines) == 1:
                                lines.append(f"  - *{method['docstring'].strip()}*")
                            else:
                                # å¤šè¡Œæ–‡æ¡£å­—ç¬¦ä¸²ï¼Œç”¨ä»£ç å—æ ¼å¼æ˜¾ç¤º
                                lines.append("  - **Docstring:**")
                                lines.append("  ```")
                                for doc_line in docstring_lines:
                                    lines.append(f"  {doc_line}")
                                lines.append("  ```")
                    lines.append("")

                # Properties
                if cls["properties"]:
                    lines.append(f"**Properties ({len(cls['properties'])}):**")
                    for prop in cls["properties"]:
                        return_str = f" -> {prop['return_type']}" if prop["return_type"] else ""
                        lines.append(f"- `@property {prop['name']}{return_str}`")
                    lines.append("")

                # ç±»å˜é‡
                if cls["class_variables"]:
                    lines.append(f"**Class Variables ({len(cls['class_variables'])}):**")
                    for var in cls["class_variables"]:
                        type_str = f": {var['type']}" if var["type"] else ""
                        value_str = f" = {var['value']}" if var.get("value") else ""
                        lines.append(f"- `{var['name']}{type_str}{value_str}`")
                    lines.append("")

        # é¡¶çº§å‡½æ•°
        if metadata.get("functions"):
            public_functions = [f for f in metadata["functions"] if f["is_public"]]
            if public_functions:
                lines.append(f"#### ğŸ”§ Public Functions ({len(public_functions)})\n")
                for func in public_functions:
                    params_str = self._format_parameters(func["parameters"])
                    return_str = f" -> {func['return_type']}" if func["return_type"] else ""
                    async_str = "async " if func["type"] == "async_function" else ""
                    
                    decorators_str = ""
                    if func["decorators"]:
                        decorators_str = " " + " ".join([f"`{d}`" for d in func["decorators"]])
                    
                    lines.append(f"- `{async_str}def {func['name']}({params_str}){return_str}`{decorators_str}")
                    lines.append(f"  - *Line: {func['lineno']}*")
                    
                    if func["docstring"]:
                        # å¦‚æœæ–‡æ¡£å­—ç¬¦ä¸²åªæœ‰ä¸€è¡Œï¼Œç”¨ç®€çŸ­æ ¼å¼æ˜¾ç¤º
                        docstring_lines = func["docstring"].split("\n")
                        if len(docstring_lines) == 1:
                            lines.append(f"  - *{func['docstring'].strip()}*")
                        else:
                            # å¤šè¡Œæ–‡æ¡£å­—ç¬¦ä¸²ï¼Œç”¨ä»£ç å—æ ¼å¼æ˜¾ç¤º
                            lines.append("  - **Docstring:**")
                            lines.append("  ```")
                            for doc_line in docstring_lines:
                                lines.append(f"  {doc_line}")
                            lines.append("  ```")
                    lines.append("")

        lines.append("\n---\n")
        return "\n".join(lines)

    def _format_parameters(self, parameters: list) -> str:
        """æ ¼å¼åŒ–å‡½æ•°å‚æ•°åˆ—è¡¨"""
        param_strs = []
        for param in parameters:
            param_str = param["name"]
            if param["type"]:
                param_str += f": {param['type']}"
            if param["default"]:
                param_str += f" = {param['default']}"
            param_strs.append(param_str)
        return ", ".join(param_strs)

    def merge_from_files_with_metadata(
        self,
        relative_file_name_list: typing.List[str],
        as_title: str,
        project_root: typing.Union[os.PathLike, str] = None,
        include_ast_metadata: bool = True,
        include_file_text: bool = True,
    ) -> "AiMdGenerator":
        """
        åˆå¹¶æ–‡ä»¶å†…å®¹åˆ° Markdownï¼Œå¯¹äº Python æ–‡ä»¶ä¼šé¢å¤–ç”Ÿæˆ AST å…ƒæ•°æ®
        
        Args:
            project_root: é¡¹ç›®æ ¹ç›®å½•
            relative_file_name_list: ç›¸å¯¹æ–‡ä»¶è·¯å¾„åˆ—è¡¨
            as_title: æ ‡é¢˜
            include_ast_metadata: æ˜¯å¦åŒ…å« AST å…ƒæ•°æ®ï¼ˆä»…å¯¹ .py æ–‡ä»¶ï¼‰
            include_file_text: æ˜¯å¦åŒ…å«å®Œæ•´æ–‡ä»¶æºç ï¼ˆFalse æ—¶åªæ˜¾ç¤ºå…ƒæ•°æ®ï¼‰
        """
        self._check_project_name()
        project_root =  project_root or self.project_root
        file_text_list = []
        project_root_path = NbPath(project_root).resolve()
        
        for relative_file_name in relative_file_name_list:
            file = (project_root_path / relative_file_name).resolve()
            if not file.exists():
                raise FileNotFoundError(f"File {file} not found.")
            if file.is_file() and file.is_text():
                relative_file_name_posix = file.relative_to(project_root_path).as_posix()
                try:
                    text = file.read_text()
                except Exception as e:
                    self.logger.error(f"Error reading file {file}: {e}")
                    text = ""
                
                file_text_list.append([file, relative_file_name_posix, file.suffix, text])
                self.logger.debug(f"need merged file: {file}")
            else:
                raise ValueError(f"File {file} is not a text file.")
        
        str_list = []
        if file_text_list:
            str_list.extend(self._generate_markdown_header(as_title, file_text_list))

        for file, relative_file_name_posix, suffix, text in file_text_list:
            # å¦‚æœä¸åŒ…å«æ–‡ä»¶å†…å®¹ï¼Œåªè¾“å‡ºå…ƒæ•°æ®ï¼ˆä»…å¯¹ Python æ–‡ä»¶ï¼‰
            if not include_file_text:
                if suffix == ".py" and include_ast_metadata:
                    # åªæ˜¾ç¤ºå…ƒæ•°æ®ï¼Œä¸æ˜¾ç¤ºæºç 
                    metadata = self._parse_python_file_ast(file)
                    metadata_md = self._format_py_metadata_as_markdown(metadata, relative_file_name_posix)
                    str_list.append(metadata_md)
                    str_list.append("\n")
                # é Python æ–‡ä»¶è·³è¿‡
                continue
            
            # æ­£å¸¸æµç¨‹ï¼šåŒ…å«æ–‡ä»¶å†…å®¹
            str_list.append(f"--- **start of file: {relative_file_name_posix}** --- \n")
            
            # å¯¹äº Python æ–‡ä»¶ï¼Œæ·»åŠ  AST å…ƒæ•°æ®
            if suffix == ".py" and include_ast_metadata:
                metadata = self._parse_python_file_ast(file)
                metadata_md = self._format_py_metadata_as_markdown(metadata, relative_file_name_posix)
                str_list.append(metadata_md)
            
            # æ·»åŠ å®Œæ•´çš„æ–‡ä»¶å†…å®¹
            if suffix == ".md":
                str_list.append(text + "\n")
            else:
                lang = self.suffix__lang_map.get(suffix, "text")
                str_list.append(f"```{lang}\n{text}\n```\n")

            str_list.append(f"--- **end of file: {relative_file_name_posix}** --- \n")
            str_list.append("---\n\n")

        self.append_text('\n'.join(str_list))
        self.ensure_utf8_bom()
        return self
